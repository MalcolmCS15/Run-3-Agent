{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0bb4b5f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All imports successful for Run3 project!\n",
      "TensorFlow version: 2.15.0\n",
      "NumPy version: 1.26.4\n",
      "OpenCV version: 4.10.0\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from collections import deque\n",
    "\n",
    "# -------- Image processing -----\n",
    "import pyautogui\n",
    "import numpy as np\n",
    "import cv2\n",
    "import mss\n",
    "\n",
    "# -------- TensorFlow / Keras ----\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model\n",
    "\n",
    "# -------- Misc / Debug ----------\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"All imports successful for Run3 project!\")\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "print(f\"OpenCV version: {cv2.__version__}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "3e43e794",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Establish some variables and params for later\n",
    "\n",
    "#number of frames to feed model at a time. We input to the model the FRAME_STACK most recent frames\n",
    "FRAME_STACK = 4\n",
    "\n",
    "#variables for the location of the run 3 game on the screen. This is for Malcolms computer, if its diff for u make new vars\n",
    "TOP_X = 275\n",
    "TOP_Y = 195\n",
    "WIDTH = 725\n",
    "HEIGHT = 545\n",
    "\n",
    "GAMEOVER_X = 860\n",
    "GAMEOVER_Y = 435\n",
    "GAMEOVER_W = 70\n",
    "GAMEOVER_H = 45\n",
    "\n",
    "RUNWAY_X = 600\n",
    "RUNWAY_Y = 480\n",
    "RUNWAY_W = 75\n",
    "RUNWAY_H = 180\n",
    "\n",
    "#Which device is running the game. Add ur own if u wanna train. So we dont have to go all the way through everything and change\n",
    "MAC_LAPTOP = True \n",
    "MAC_MONITOR = False\n",
    "\n",
    "if MAC_LAPTOP: \n",
    "    TOP_X = 275\n",
    "    TOP_Y = 195\n",
    "    WIDTH = 725\n",
    "    HEIGHT = 545\n",
    "\n",
    "    GAMEOVER_X = 860\n",
    "    GAMEOVER_Y = 435\n",
    "    GAMEOVER_W = 70\n",
    "    GAMEOVER_H = 45\n",
    "\n",
    "    RUNWAY_X = 625\n",
    "    RUNWAY_Y = 480\n",
    "    RUNWAY_W = 75\n",
    "    RUNWAY_H = 200\n",
    "\n",
    "\n",
    "#resolution of the image were resizing to. This affects the input to our neural net directly.\n",
    "RESOLUTION = 96\n",
    "\n",
    "#number of actions the model can take. This is a super important thing to change if the model isnt training well. As of 12/5 were starting\n",
    "#with the model being able to take [no action, L_small, R_small, U_small, L_med, R_med ...etc.]\n",
    "NUM_ACTIONS = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "e191780a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def preprocess_frame(image, resize=(RESOLUTION, RESOLUTION), gray=True):\n",
    "    \"\"\"\n",
    "    Captures a screenshot of the given region, converts to grayscale, resizes.\n",
    "    Returns numpy array of shape (resize[1], resize[0]).\n",
    "    \"\"\"\n",
    "    if gray:\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Resize deterministically\n",
    "    small = cv2.resize(image, resize, interpolation=cv2.INTER_AREA)\n",
    "    \n",
    "    return small\n",
    "\n",
    "def stack_frames(frames, new_frame, stack_size=FRAME_STACK):\n",
    "    \"\"\"\n",
    "    Maintains a stack of frames to capture motion.\n",
    "    frames: deque of previous frames\n",
    "    new_frame: newest preprocessed frame\n",
    "    Returns stack of frames\n",
    "    \"\"\"\n",
    "    if len(frames) == 0:\n",
    "        # Initialize with repeated frame\n",
    "        for _ in range(stack_size):\n",
    "            frames.append(new_frame)\n",
    "    else:\n",
    "        frames.append(new_frame)\n",
    "        if len(frames) > stack_size:\n",
    "            frames.popleft()\n",
    "    return np.stack(frames, axis=0)\n",
    "\n",
    "#TEST to see if screen grab is working\n",
    "\n",
    "time.sleep(3)\n",
    "\n",
    "sct = mss.mss()\n",
    "monitor = {\n",
    "    \"top\": TOP_Y,\n",
    "    \"left\": TOP_X,\n",
    "    \"width\": WIDTH,\n",
    "    \"height\": HEIGHT\n",
    "}\n",
    "runway = {\n",
    "    \"top\": RUNWAY_Y,\n",
    "    \"left\": RUNWAY_X,\n",
    "    \"width\": RUNWAY_W,\n",
    "    \"height\": RUNWAY_H\n",
    "}\n",
    "screenshot = np.array(sct.grab(monitor))\n",
    "img = cv2.cvtColor(np.array(screenshot), cv2.COLOR_BGRA2BGR)\n",
    "processed = preprocess_frame(img)\n",
    "plt.imshow(processed, cmap=\"gray\")\n",
    "plt.title(\"Preprocessed frame (grayscale + resized)\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "\n",
    "screenshot = np.array(sct.grab(runway))\n",
    "img = cv2.cvtColor(np.array(screenshot), cv2.COLOR_BGRA2BGR)\n",
    "processed = preprocess_frame(img)\n",
    "plt.imshow(processed, cmap=\"gray\")\n",
    "plt.title(\"Runway preview\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "b158ff17",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PPOActorCritic(tf.keras.Model):\n",
    "    def __init__(self, input_channels=FRAME_STACK, num_actions=NUM_ACTIONS):\n",
    "        super(PPOActorCritic, self).__init__()\n",
    "\n",
    "        # TensorFlow expects channels-last â†’ (RESOLUTION, RESOLUTION, C)\n",
    "        self.input_channels = input_channels\n",
    "        self.num_actions = num_actions\n",
    "        \n",
    "        # ---------- CNN Backbone ----------\n",
    "        self.conv1 = layers.Conv2D(32, kernel_size=8, strides=4, activation='relu')\n",
    "        self.conv2 = layers.Conv2D(64, kernel_size=4, strides=2, activation='relu')\n",
    "        self.conv3 = layers.Conv2D(64, kernel_size=3, strides=1, activation='relu')\n",
    "\n",
    "        #max pool? think about max pool if we use a larger resolution. But these convs also scale down.\n",
    "\n",
    "        # compute flatten size\n",
    "        self._conv_out_size = self._get_conv_out((RESOLUTION, RESOLUTION, input_channels))\n",
    "\n",
    "        # ---------- Shared Fully Connected ----------\n",
    "        self.fc = layers.Dense(512, activation='relu')\n",
    "\n",
    "        # ---------- Actor Head ----------\n",
    "        self.actor_fc1 = layers.Dense(64, activation='relu')\n",
    "        self.actor_logits = layers.Dense(num_actions, activation=None)\n",
    "\n",
    "        # ---------- Critic Head ----------\n",
    "        self.critic_fc1 = layers.Dense(64, activation='relu')\n",
    "        self.critic_value = layers.Dense(1, activation=None)\n",
    "\n",
    "    # -------------------------------------------------\n",
    "    # Compute conv output size by running dummy tensor. This saves us work if we change the CNN structure\n",
    "    # -------------------------------------------------\n",
    "    def _get_conv_out(self, shape):\n",
    "        dummy = tf.zeros((1, *shape), dtype=tf.float32)\n",
    "        x = self.conv1(dummy)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        return int(np.prod(x.shape[1:]))\n",
    "\n",
    "    # -------------------------------------------------\n",
    "    # Forward pass\n",
    "    # -------------------------------------------------\n",
    "    def call(self, x):\n",
    "        \"\"\"\n",
    "        x expected as (batch, RESOLUTION, RESOLUTION, 4)\n",
    "        \"\"\"\n",
    "        x = tf.cast(x, tf.float32) / 255.0 #normalize to [0,1]\n",
    "\n",
    "        # CNN backbone\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "\n",
    "        # Flatten\n",
    "        x = tf.reshape(x, (x.shape[0], -1))\n",
    "\n",
    "        # Shared FC\n",
    "        x = self.fc(x)\n",
    "\n",
    "        # ---- Actor ----\n",
    "        a = self.actor_fc1(x)\n",
    "        logits = self.actor_logits(a)\n",
    "\n",
    "        # ---- Critic ----\n",
    "        c = self.critic_fc1(x)\n",
    "        value = self.critic_value(c)\n",
    "\n",
    "        return logits, value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "026a525c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Run3Env:\n",
    "    def __init__(self, region=(TOP_X, TOP_Y, WIDTH, HEIGHT), frame_stack=FRAME_STACK):\n",
    "        self.region = region\n",
    "        self.frame_stack = frame_stack #integer, not the actual stack. Do we need instance var?\n",
    "        self.frames = deque(maxlen=frame_stack)\n",
    "\n",
    "        self.sct = mss.mss()\n",
    "        self.monitor = {\n",
    "            \"top\": region[1],      # TOP_Y\n",
    "            \"left\": region[0],     # TOP_X\n",
    "            \"width\": region[2],    # WIDTH\n",
    "            \"height\": region[3]    # HEIGHT\n",
    "        }\n",
    "        self.prev_platform_score = 0.0\n",
    "\n",
    "    # -------------------------\n",
    "    # Reset environment\n",
    "    # -------------------------\n",
    "    def reset(self):\n",
    "        # Click to restart game. 900,650 is just off the screen a bit, click twice to bypass the \"continue\" and \"score\". \n",
    "        #we can also press a button to make it better for everyones computer\n",
    "        time.sleep(.7)\n",
    "        pyautogui.click(900, 650)\n",
    "        time.sleep(.7)\n",
    "        pyautogui.click(900, 650)\n",
    "        self.frames.clear()\n",
    "\n",
    "        # Get initial observation\n",
    "        raw = self.capture_raw()\n",
    "        processed = preprocess_frame(raw) #function defined at the top\n",
    "        stacked = stack_frames(self.frames, processed)\n",
    "        \n",
    "        self.prev_platform_score = self.runway_reward(raw)\n",
    "\n",
    "        return np.transpose(stacked, (1, 2, 0))  # (RESOLUTION, RESOLUTION, FRAME_STACK). \n",
    "\n",
    "    # -------------------------\n",
    "    # Capture raw screenshot\n",
    "    # -------------------------\n",
    "    def capture_raw(self):\n",
    "        screenshot = np.array(self.sct.grab(self.monitor))\n",
    "        # mss returns BGRA, convert to BGR. Also mss is much faster than pyautogui so we use it for more fps.\n",
    "        img = cv2.cvtColor(screenshot, cv2.COLOR_BGRA2BGR)\n",
    "        return img\n",
    "\n",
    "    # -------------------------\n",
    "    # Detect game over\n",
    "    # -------------------------\n",
    "    def game_over(self, raw_frame): #FIX\n",
    "        \"\"\"Check if dialog region is white\"\"\"\n",
    "        # Extract region. Note hard coded values are for macs laptop, its a region of the screen where its all white on game over.\n",
    "        tlx = GAMEOVER_X - TOP_X\n",
    "        tly = GAMEOVER_Y - TOP_Y\n",
    "        w = GAMEOVER_W\n",
    "        h = GAMEOVER_H\n",
    "        roi = raw_frame[tly:tly+h, tlx:tlx+w]\n",
    "        \n",
    "        # Check if white directly on BGR image\n",
    "        mean_val = roi.mean()  # Average across all pixels AND all channels\n",
    "        \n",
    "        # If all channels are ~255, mean will be ~255\n",
    "        return mean_val > 250\n",
    "\n",
    "    def runway_reward(self, raw_frame):\n",
    "        tlx = RUNWAY_X - TOP_X\n",
    "        tly = RUNWAY_Y - TOP_Y\n",
    "        w = RUNWAY_W\n",
    "        h = RUNWAY_H\n",
    "        roi = raw_frame[tly:tly+h, tlx:tlx+w]\n",
    "\n",
    "        if len(roi.shape) == 3: #grayscale\n",
    "            roi_gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
    "        else:\n",
    "            roi_gray = roi\n",
    "        \n",
    "        platform_pixels = np.sum(roi_gray > 30)\n",
    "        total_pixels = roi_gray.size\n",
    "        platform_ratio = platform_pixels / total_pixels\n",
    "        \n",
    "        return platform_ratio #small reward based on % of runway occupied.\n",
    "\n",
    "    # -------------------------\n",
    "    # Take one step in environment \n",
    "    # -------------------------\n",
    "    def step(self, action): #NOT FINISHED DONT TOUCH\n",
    "        # step_start = time.time()\n",
    "        self._execute_action(action)\n",
    "\n",
    "        # Capture new frame\n",
    "        raw = self.capture_raw()\n",
    "\n",
    "        done = self.game_over(raw) #Boolean var\n",
    "        \n",
    "        platform_score = self.runway_reward(raw)\n",
    "                # NEW: change in platform score since last step\n",
    "        delta_platform = platform_score - self.prev_platform_score\n",
    "        self.prev_platform_score = platform_score\n",
    "\n",
    "        # Reward logic\n",
    "        if done:\n",
    "            reward = -10.0\n",
    "        else:\n",
    "            # Only reward improvements + small per-step time penalty\n",
    "            progress_reward = max(delta_platform, 0.0) * 3.0   # tweak 3.0 as needed\n",
    "            time_penalty = -0.01                               # cost per step to discourage camping\n",
    "\n",
    "            reward = progress_reward + time_penalty\n",
    "\n",
    "            # keep a small penalty for 'no action' if you like\n",
    "            if action == 0:\n",
    "                reward -= 0.02\n",
    "\n",
    "        # Preprocess\n",
    "        processed = preprocess_frame(raw)\n",
    "        stacked = stack_frames(self.frames, processed)\n",
    "        \n",
    "        state = np.transpose(stacked, (1, 2, 0))  # (REOSLUTION,RESOLUTION,STACK_FRAMES)\n",
    "\n",
    "        # TARGET_TIMESTEP = 0.33 \n",
    "        # elapsed = time.time() - step_start\n",
    "        # if elapsed < TARGET_TIMESTEP:\n",
    "        #     time.sleep(TARGET_TIMESTEP - elapsed)\n",
    "\n",
    "        return state, reward, done, {}\n",
    "\n",
    "    def _execute_action(self, action):\n",
    "        \"\"\"Execute action with proper hold durations\"\"\"\n",
    "        # Map actions to (key, duration_seconds)\n",
    "        action_config = {\n",
    "            0: (None, 0),           # No action\n",
    "            1: ('left', 0.05),       # Left short - 100ms\n",
    "            2: ('right', 0.05),      # Right short\n",
    "            3: ('up', 0.05),         # Up short (jump)\n",
    "            4: ('left', 0.1),      # Left medium - 250ms\n",
    "            5: ('right', 0.1),     # Right medium\n",
    "            6: ('up', 0.1),        # Up medium\n",
    "            7: ('left', 0.25),       # Left long - 500ms\n",
    "            8: ('right', 0.25),      # Right long\n",
    "            9: ('up', 0.25),         # Up long\n",
    "        }\n",
    "        \n",
    "        key, duration = action_config[action]\n",
    "        \n",
    "        if key is not None:\n",
    "            pyautogui.keyDown(key)\n",
    "            time.sleep(duration)\n",
    "            pyautogui.keyUp(key)\n",
    "        time.sleep(0.25-duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "4956b50f-186c-4637-9921-97c2687ae8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #JUST FOR TESTING THINGS WORK WHEN RUNNING THE GAME.\n",
    "# sct = mss.mss()\n",
    "# monitor = {\n",
    "#     \"top\": TOP_Y,\n",
    "#     \"left\": TOP_X,\n",
    "#     \"width\": WIDTH,\n",
    "#     \"height\": HEIGHT\n",
    "# }\n",
    "# num_g_over = 0\n",
    "\n",
    "# def test_game_over(raw_frame):\n",
    "#     \"\"\"Check if dialog region is white\"\"\"\n",
    "#     # Extract region\n",
    "#     tlx = 860 - TOP_X\n",
    "#     tly = 435 - TOP_Y\n",
    "#     w = 70\n",
    "#     h = 45\n",
    "#     roi = raw_frame[tly:tly+h, tlx:tlx+w]\n",
    "    \n",
    "#     # Check if white directly on BGR image\n",
    "#     mean_val = roi.mean()  # Average across all pixels AND all channels\n",
    "    \n",
    "#     # If all channels are ~255, mean will be ~255\n",
    "#     return mean_val > 250\n",
    "\n",
    "# def test_runway_reward(raw_frame):\n",
    "#     tlx = RUNWAY_X - TOP_X\n",
    "#     tly = RUNWAY_Y - TOP_Y\n",
    "#     w = RUNWAY_W\n",
    "#     h = RUNWAY_H\n",
    "#     roi = raw_frame[tly:tly+h, tlx:tlx+w]\n",
    "\n",
    "#     if len(roi.shape) == 3: #grayscale\n",
    "#         roi_gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
    "#     else:\n",
    "#         roi_gray = roid\n",
    "    \n",
    "#     platform_pixels = np.sum(roi_gray > 30)\n",
    "#     total_pixels = roi_gray.size\n",
    "#     platform_ratio = platform_pixels / total_pixels\n",
    "    \n",
    "#     return platform_ratio\n",
    "\n",
    "# while True:\n",
    "#     start_time = time.time()\n",
    "#     screenshot = np.array(sct.grab(monitor))\n",
    "#     img = cv2.cvtColor(screenshot, cv2.COLOR_BGRA2BGR)\n",
    "#     if test_game_over(img):\n",
    "#         num_g_over += 1\n",
    "#         print(f\"\\rgame over {num_g_over}\", end='', flush=True)\n",
    "#         time.sleep(0.7)\n",
    "#         pyautogui.click(900, 650)\n",
    "#         time.sleep(0.7)\n",
    "#         pyautogui.click(900, 650)\n",
    "#     else:\n",
    "#         pass\n",
    "#         # print(test_runway_reward(img))\n",
    "#     elapsed = time.time() - start_time\n",
    "#     if elapsed < 1:\n",
    "#             time.sleep(1 - elapsed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "3de65712",
   "metadata": {},
   "outputs": [],
   "source": [
    "#IHAVENT CHECKED THE CLASS BELOW YET THIS IS JUST CHAT SO DONT TREAT IT AS SOLIDLY IMPLEMENTED\n",
    "\n",
    "class PPOBuffer:\n",
    "    def __init__(self, size, obs_shape, gamma=0.99, lam=0.95):\n",
    "        \"\"\"\n",
    "        size      : number of steps per rollout\n",
    "        obs_shape : shape of observation e.g. (RESOLUTION, RESOLUTION, FRAME_STACK)\n",
    "        gamma     : discount factor\n",
    "        lam       : GAE lambda\n",
    "        \"\"\"\n",
    "        self.size = size\n",
    "        self.gamma = gamma\n",
    "        self.lam = lam\n",
    "\n",
    "        # Allocate buffers\n",
    "        self.obs_buf = np.zeros((size, *obs_shape), dtype=np.float32)\n",
    "        self.act_buf = np.zeros(size, dtype=np.int32)\n",
    "        self.rew_buf = np.zeros(size, dtype=np.float32)\n",
    "        self.done_buf = np.zeros(size, dtype=np.float32)\n",
    "        self.val_buf = np.zeros(size, dtype=np.float32)\n",
    "        self.logp_buf = np.zeros(size, dtype=np.float32)\n",
    "\n",
    "        # To be computed later\n",
    "        self.adv_buf = np.zeros(size, dtype=np.float32)\n",
    "        self.ret_buf = np.zeros(size, dtype=np.float32)\n",
    "\n",
    "        self.ptr = 0        # next index to write\n",
    "        self.path_start = 0 # start index of current trajectory\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # Store one step of rollout data\n",
    "    # ---------------------------------------------------------\n",
    "    def store(self, obs, act, rew, done, val, logp):\n",
    "        assert self.ptr < self.size, \"PPOBuffer overflow!\"\n",
    "        self.obs_buf[self.ptr] = obs\n",
    "        self.act_buf[self.ptr] = act\n",
    "        self.rew_buf[self.ptr] = rew\n",
    "        self.done_buf[self.ptr] = done\n",
    "        self.val_buf[self.ptr] = val\n",
    "        self.logp_buf[self.ptr] = logp\n",
    "        self.ptr += 1\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # Finish trajectory and compute GAE + returns\n",
    "    # last_val is the value of the final observation (0 if done)\n",
    "    # ---------------------------------------------------------\n",
    "    def finish_trajectory(self, last_val=0):\n",
    "        \"\"\"\n",
    "        Called at trajectory end or when episode completes.\n",
    "        Computes GAE advantage & discounted returns.\n",
    "        \"\"\"\n",
    "        i1 = self.path_start\n",
    "        i2 = self.ptr\n",
    "\n",
    "        rewards = np.append(self.rew_buf[i1:i2], last_val)\n",
    "        values  = np.append(self.val_buf[i1:i2], last_val)\n",
    "\n",
    "        # GAE-Lambda advantage calculation\n",
    "        deltas = rewards[:-1] + self.gamma * values[1:] - values[:-1]\n",
    "\n",
    "        adv = np.zeros_like(deltas)\n",
    "        last_gae = 0\n",
    "        for t in reversed(range(len(deltas))):\n",
    "            last_gae = deltas[t] + self.gamma * self.lam * last_gae * (1 - self.done_buf[i1 + t])\n",
    "            adv[t] = last_gae\n",
    "\n",
    "        self.adv_buf[i1:i2] = adv\n",
    "        self.ret_buf[i1:i2] = adv + self.val_buf[i1:i2]\n",
    "\n",
    "        self.path_start = self.ptr  # next trajectory starts here\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # Retrieve all data, normalize adv, and reset pointer\n",
    "    # ---------------------------------------------------------\n",
    "    def prepare_for_training(self):\n",
    "        \"\"\"\n",
    "        Call this after all trajectories are collected and before get().\n",
    "        Normalizes advantages across the entire buffer.\n",
    "        \"\"\"\n",
    "        assert self.ptr == self.size, \"Buffer not full!\"\n",
    "    \n",
    "        # Normalize advantages\n",
    "        adv_mean = self.adv_buf.mean()\n",
    "        adv_std = self.adv_buf.std() + 1e-8\n",
    "        self.adv_buf = (self.adv_buf - adv_mean) / adv_std\n",
    "\n",
    "        \n",
    "    def get(self, batch_size=64):\n",
    "        \"\"\"Returns batches of rollout data.\"\"\"\n",
    "        assert self.ptr == self.size, \"Buffer not full!\"\n",
    "    \n",
    "        return {\n",
    "            'obs': self.obs_buf,\n",
    "            'act': self.act_buf,\n",
    "            'adv': self.adv_buf,\n",
    "            'ret': self.ret_buf,\n",
    "            'logp': self.logp_buf,\n",
    "            'val': self.val_buf\n",
    "        }\n",
    "    \n",
    "    def reset(self):\n",
    "        \"\"\"\n",
    "        Reset buffer for next rollout collection.\n",
    "        Call this after training is done for the epoch.\n",
    "        \"\"\"\n",
    "        self.ptr = 0\n",
    "        self.path_start = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "4dcc7a91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Configuration:\n",
      "  Learning Rate: 0.0003\n",
      "  Steps per Epoch: 512\n",
      "  Total Epochs: 150\n",
      "  Gamma: 0.99, GAE Lambda: 0.95\n",
      "  Clip Ratio: 0.2\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# TRAINING CONFIGURATION AND HYPERPARAMETERS\n",
    "# ============================================================================\n",
    "\n",
    "# Training hyperparameters\n",
    "LEARNING_RATE = 3e-4\n",
    "CLIP_RATIO = 0.2\n",
    "VALUE_COEF = 0.5\n",
    "ENTROPY_COEF = 0.025\n",
    "MAX_GRAD_NORM = 0.5\n",
    "\n",
    "# Rollout parameters\n",
    "STEPS_PER_EPOCH = 512  # Number of steps per training epoch\n",
    "TRAIN_EPOCHS = 150      # Total number of epochs\n",
    "MINI_BATCH_SIZE = 64    # Size of mini-batches for SGD\n",
    "UPDATE_EPOCHS = 5      # Number of epochs to train on each batch\n",
    "\n",
    "# Discount and GAE\n",
    "GAMMA = 0.99\n",
    "GAE_LAMBDA = 0.95\n",
    "\n",
    "# Logging and checkpointing\n",
    "LOG_INTERVAL = 3          # Log every N epochs\n",
    "SAVE_INTERVAL = 25         # Save model every N epochs\n",
    "EVAL_EPISODES = 10          # Number of episodes for evaluation\n",
    "\n",
    "# Create directories for saving\n",
    "import os\n",
    "os.makedirs('checkpoints', exist_ok=True)\n",
    "os.makedirs('logs', exist_ok=True)\n",
    "\n",
    "print(\"Training Configuration:\")\n",
    "print(f\"  Learning Rate: {LEARNING_RATE}\")\n",
    "print(f\"  Steps per Epoch: {STEPS_PER_EPOCH}\")\n",
    "print(f\"  Total Epochs: {TRAIN_EPOCHS}\")\n",
    "print(f\"  Gamma: {GAMMA}, GAE Lambda: {GAE_LAMBDA}\")\n",
    "print(f\"  Clip Ratio: {CLIP_RATIO}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "a9d9d191",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training functions defined!\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# PPO TRAINING FUNCTIONS\n",
    "# ============================================================================\n",
    "\n",
    "def compute_loss(model, obs, actions, advantages, returns, old_log_probs, old_values):\n",
    "    \"\"\"\n",
    "    Compute PPO loss with clipping.\n",
    "    \n",
    "    Args:\n",
    "        model: PPOActorCritic model\n",
    "        obs: observations (batch_size, H, W, C)\n",
    "        actions: actions taken (batch_size,)\n",
    "        advantages: advantage estimates (batch_size,)\n",
    "        returns: discounted returns (batch_size,)\n",
    "        old_log_probs: old action log probabilities (batch_size,)\n",
    "        old_values: old value estimates (batch_size,)\n",
    "    \n",
    "    Returns:\n",
    "        total_loss, policy_loss, value_loss, entropy\n",
    "    \"\"\"\n",
    "    # Get current policy and value predictions\n",
    "    logits, values = model(obs, training=True)\n",
    "    values = tf.squeeze(values, axis=-1)\n",
    "    \n",
    "    # Compute log probabilities of actions\n",
    "    action_dist = tf.compat.v1.distributions.Categorical(logits=logits)\n",
    "    log_probs = action_dist.log_prob(actions)\n",
    "    \n",
    "    # Compute entropy for exploration bonus\n",
    "    entropy = tf.reduce_mean(action_dist.entropy())\n",
    "    \n",
    "    # Compute ratio for PPO\n",
    "    ratio = tf.exp(log_probs - old_log_probs)\n",
    "    \n",
    "    # Normalize advantages\n",
    "    advantages = (advantages - tf.reduce_mean(advantages)) / (tf.math.reduce_std(advantages) + 1e-8)\n",
    "    \n",
    "    # Policy loss with clipping\n",
    "    policy_loss_1 = -advantages * ratio\n",
    "    policy_loss_2 = -advantages * tf.clip_by_value(ratio, 1 - CLIP_RATIO, 1 + CLIP_RATIO)\n",
    "    policy_loss = tf.reduce_mean(tf.maximum(policy_loss_1, policy_loss_2))\n",
    "    \n",
    "    # Value loss with clipping\n",
    "    value_pred_clipped = old_values + tf.clip_by_value(\n",
    "        values - old_values, -CLIP_RATIO, CLIP_RATIO\n",
    "    )\n",
    "    value_loss_1 = tf.square(returns - values)\n",
    "    value_loss_2 = tf.square(returns - value_pred_clipped)\n",
    "    value_loss = 0.5 * tf.reduce_mean(tf.maximum(value_loss_1, value_loss_2))\n",
    "    \n",
    "    # Total loss\n",
    "    total_loss = policy_loss + VALUE_COEF * value_loss - ENTROPY_COEF * entropy\n",
    "    \n",
    "    return total_loss, policy_loss, value_loss, entropy\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def train_step(model, optimizer, obs, actions, advantages, returns, old_log_probs, old_values):\n",
    "    \"\"\"\n",
    "    Single training step with gradient computation.\n",
    "    \"\"\"\n",
    "    with tf.GradientTape() as tape:\n",
    "        total_loss, policy_loss, value_loss, entropy = compute_loss(\n",
    "            model, obs, actions, advantages, returns, old_log_probs, old_values\n",
    "        )\n",
    "    \n",
    "    # Compute gradients\n",
    "    gradients = tape.gradient(total_loss, model.trainable_variables)\n",
    "    \n",
    "    # Clip gradients\n",
    "    gradients, _ = tf.clip_by_global_norm(gradients, MAX_GRAD_NORM)\n",
    "    \n",
    "    # Apply gradients\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    \n",
    "    return total_loss, policy_loss, value_loss, entropy\n",
    "\n",
    "\n",
    "print(\"Training functions defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "eb306cba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rollout collection function defined!\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# DATA COLLECTION FUNCTION\n",
    "# ============================================================================\n",
    "\n",
    "def collect_rollout(env, model, buffer, num_steps):\n",
    "    \"\"\"\n",
    "    Collect trajectories by running the current policy in the environment.\n",
    "    \n",
    "    Args:\n",
    "        env: Run3Env instance\n",
    "        model: PPOActorCritic model\n",
    "        buffer: PPOBuffer instance\n",
    "        num_steps: number of steps to collect\n",
    "    \n",
    "    Returns:\n",
    "        ep_returns: list of episode returns\n",
    "        ep_lengths: list of episode lengths\n",
    "    \"\"\"\n",
    "    buffer.reset()  # Clear the buffer\n",
    "    \n",
    "    ep_returns = []\n",
    "    ep_lengths = []\n",
    "    current_ep_return = 0\n",
    "    current_ep_length = 0\n",
    "    \n",
    "    # Reset environment\n",
    "    obs = env.reset()\n",
    "    \n",
    "    for step in range(num_steps):\n",
    "        # Get action from policy\n",
    "        # Get action from policy\n",
    "        obs_tensor = tf.expand_dims(obs, axis=0)  # Add batch dimension\n",
    "        logits, value = model(obs_tensor, training=False)\n",
    "\n",
    "# Sample action from distribution (use logits, not probs!)\n",
    "        action_dist = tf.compat.v1.distributions.Categorical(logits=logits)\n",
    "        action_tensor = action_dist.sample()[0]\n",
    "        action = action_tensor.numpy()\n",
    "        log_prob = action_dist.log_prob(action_tensor).numpy()\n",
    "        value = value.numpy()[0, 0]\n",
    "        \n",
    "        # Take action in environment\n",
    "        next_obs, reward, done, info = env.step(action)\n",
    "        \n",
    "        # Store transition\n",
    "        buffer.store(obs, action, reward, done, value, log_prob)\n",
    "        \n",
    "        current_ep_return += reward\n",
    "        current_ep_length += 1\n",
    "        \n",
    "        obs = next_obs\n",
    "        \n",
    "        if done:\n",
    "            # Episode finished\n",
    "            buffer.finish_trajectory(0)  # Terminal state has value 0\n",
    "            ep_returns.append(current_ep_return)\n",
    "            ep_lengths.append(current_ep_length)\n",
    "            \n",
    "            # Reset for next episode\n",
    "            obs = env.reset()\n",
    "            current_ep_return = 0\n",
    "            current_ep_length = 0\n",
    "    \n",
    "    # If we ended mid-episode, bootstrap the value\n",
    "    if current_ep_length > 0:\n",
    "        obs_tensor = tf.expand_dims(obs, axis=0)\n",
    "        _, last_value = model(obs_tensor, training=False)\n",
    "        buffer.finish_trajectory(last_value.numpy()[0, 0])\n",
    "        ep_returns.append(current_ep_return)\n",
    "        ep_lengths.append(current_ep_length)\n",
    "    \n",
    "    buffer.prepare_for_training()\n",
    "\n",
    "    return ep_returns, ep_lengths\n",
    "\n",
    "\n",
    "print(\"Rollout collection function defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "2b8254b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation function defined!\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# EVALUATION FUNCTION\n",
    "# ============================================================================\n",
    "\n",
    "def evaluate_policy(env, model, num_episodes=5):\n",
    "    \"\"\"\n",
    "    Evaluate the current policy deterministically (greedy).\n",
    "    \n",
    "    Args:\n",
    "        env: Run3Env instance\n",
    "        model: PPOActorCritic model\n",
    "        num_episodes: number of episodes to run\n",
    "    \n",
    "    Returns:\n",
    "        mean_return: average episode return\n",
    "        std_return: standard deviation of returns\n",
    "        mean_length: average episode length\n",
    "    \"\"\"\n",
    "    episode_returns = []\n",
    "    episode_lengths = []\n",
    "    \n",
    "    for ep in range(num_episodes):\n",
    "        obs = env.reset()\n",
    "        done = False\n",
    "        ep_return = 0\n",
    "        ep_length = 0\n",
    "        \n",
    "        while not done:\n",
    "            # Use greedy action (argmax)\n",
    "            obs_tensor = tf.expand_dims(obs, axis=0)\n",
    "            logits, _ = model(obs_tensor, training=False)\n",
    "            action = tf.argmax(logits[0]).numpy()\n",
    "            \n",
    "            obs, reward, done, info = env.step(action)\n",
    "            ep_return += reward\n",
    "            ep_length += 1\n",
    "            \n",
    "            # Safety: break if episode too long\n",
    "            if ep_length > 10000:\n",
    "                break\n",
    "        \n",
    "        episode_returns.append(ep_return)\n",
    "        episode_lengths.append(ep_length)\n",
    "    \n",
    "    return (\n",
    "        np.mean(episode_returns),\n",
    "        np.std(episode_returns),\n",
    "        np.mean(episode_lengths)\n",
    "    )\n",
    "\n",
    "\n",
    "print(\"Evaluation function defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "344df394",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing training components...\n",
      "Model initialized with 2,242,027 parameters\n",
      "Loaded weights from checkpoints/model_epoch_75.h5\n",
      "\n",
      "Starting training...\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# INITIALIZE TRAINING COMPONENTS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"Initializing training components...\")\n",
    "\n",
    "env = Run3Env()\n",
    "model = PPOActorCritic(input_channels=FRAME_STACK, num_actions=NUM_ACTIONS)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE)\n",
    "buffer = PPOBuffer(\n",
    "    size=STEPS_PER_EPOCH,\n",
    "    obs_shape=(RESOLUTION, RESOLUTION, FRAME_STACK),\n",
    "    gamma=GAMMA,\n",
    "    lam=GAE_LAMBDA\n",
    ")\n",
    "\n",
    "# Build model by running a forward pass\n",
    "dummy_obs = tf.random.normal((1, RESOLUTION, RESOLUTION, FRAME_STACK))\n",
    "_ = model(dummy_obs)\n",
    "print(f\"Model initialized with {model.count_params():,} parameters\")\n",
    "\n",
    "# ---- Load checkpoint weights (optional) ----\n",
    "CHECKPOINT_PATH = \"checkpoints/model_epoch_75.h5\"  # <-- put your .h5 file here\n",
    "try:\n",
    "    model.load_weights(CHECKPOINT_PATH)\n",
    "    print(f\"Loaded weights from {CHECKPOINT_PATH}\")\n",
    "except Exception as e:\n",
    "    print(f\"Could not load checkpoint at {CHECKPOINT_PATH}: {e}\")\n",
    "\n",
    "# Training metrics\n",
    "training_stats = {\n",
    "    'epoch': [],\n",
    "    'mean_return': [],\n",
    "    'mean_length': [],\n",
    "    'policy_loss': [],\n",
    "    'value_loss': [],\n",
    "    'entropy': [],\n",
    "    'eval_return': [],\n",
    "    'eval_std': []\n",
    "}\n",
    "\n",
    "print(\"\\nStarting training...\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "7c1bf418",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/q_/y2tlnq4d3gl5gqxkc15y__ym0000gn/T/ipykernel_55550/1679292621.py:40: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  self.logp_buf[self.ptr] = logp\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3/150 (262.6s)\n",
      "  Returns: 15.64 | Lengths: 17.7\n",
      "  Policy Loss: -0.0135\n",
      "  Value Loss: 48.0942\n",
      "  Entropy: 1.2781\n",
      "\n",
      "Epoch 6/150 (158.4s)\n",
      "  Returns: 994.77 | Lengths: 512.0\n",
      "  Policy Loss: -0.0013\n",
      "  Value Loss: 400.7064\n",
      "  Entropy: 0.0349\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[87]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      6\u001b[39m epoch_start_time = time.time()\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# === 1. Collect rollout data ===\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m ep_returns, ep_lengths = \u001b[43mcollect_rollout\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mSTEPS_PER_EPOCH\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     11\u001b[39m mean_return = np.mean(ep_returns) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(ep_returns) > \u001b[32m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[32m0\u001b[39m\n\u001b[32m     12\u001b[39m mean_length = np.mean(ep_lengths) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(ep_lengths) > \u001b[32m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[32m0\u001b[39m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[83]\u001b[39m\u001b[32m, line 43\u001b[39m, in \u001b[36mcollect_rollout\u001b[39m\u001b[34m(env, model, buffer, num_steps)\u001b[39m\n\u001b[32m     40\u001b[39m value = value.numpy()[\u001b[32m0\u001b[39m, \u001b[32m0\u001b[39m]\n\u001b[32m     42\u001b[39m \u001b[38;5;66;03m# Take action in environment\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m43\u001b[39m next_obs, reward, done, info = \u001b[43menv\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     45\u001b[39m \u001b[38;5;66;03m# Store transition\u001b[39;00m\n\u001b[32m     46\u001b[39m buffer.store(obs, action, reward, done, value, log_prob)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[78]\u001b[39m\u001b[32m, line 83\u001b[39m, in \u001b[36mRun3Env.step\u001b[39m\u001b[34m(self, action)\u001b[39m\n\u001b[32m     81\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mstep\u001b[39m(\u001b[38;5;28mself\u001b[39m, action): \u001b[38;5;66;03m#NOT FINISHED DONT TOUCH\u001b[39;00m\n\u001b[32m     82\u001b[39m     \u001b[38;5;66;03m# step_start = time.time()\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m83\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_execute_action\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     85\u001b[39m     \u001b[38;5;66;03m# Capture new frame\u001b[39;00m\n\u001b[32m     86\u001b[39m     raw = \u001b[38;5;28mself\u001b[39m.capture_raw()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[78]\u001b[39m\u001b[32m, line 135\u001b[39m, in \u001b[36mRun3Env._execute_action\u001b[39m\u001b[34m(self, action)\u001b[39m\n\u001b[32m    133\u001b[39m     time.sleep(duration)\n\u001b[32m    134\u001b[39m     pyautogui.keyUp(key)\n\u001b[32m--> \u001b[39m\u001b[32m135\u001b[39m time.sleep(\u001b[32m0.25\u001b[39m-duration)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# MAIN TRAINING LOOP\n",
    "# ============================================================================\n",
    "\n",
    "for epoch in range(TRAIN_EPOCHS):\n",
    "    epoch_start_time = time.time()\n",
    "    \n",
    "    # === 1. Collect rollout data ===\n",
    "    ep_returns, ep_lengths = collect_rollout(env, model, buffer, STEPS_PER_EPOCH)\n",
    "    \n",
    "    mean_return = np.mean(ep_returns) if len(ep_returns) > 0 else 0\n",
    "    mean_length = np.mean(ep_lengths) if len(ep_lengths) > 0 else 0\n",
    "    \n",
    "    # === 2. Get training data from buffer ===\n",
    "    data = buffer.get()\n",
    "    obs_buf = data['obs']\n",
    "    act_buf = data['act']\n",
    "    adv_buf = data['adv']\n",
    "    ret_buf = data['ret']\n",
    "    logp_buf = data['logp']\n",
    "    val_buf = data['val']\n",
    "    \n",
    "    # === 3. Train on the collected data ===\n",
    "    total_losses = []\n",
    "    policy_losses = []\n",
    "    value_losses = []\n",
    "    entropies = []\n",
    "    \n",
    "    # Perform multiple epochs of training on the same batch\n",
    "    for i in range(UPDATE_EPOCHS):\n",
    "        # Shuffle indices\n",
    "        indices = np.arange(len(obs_buf))\n",
    "        np.random.shuffle(indices)\n",
    "        \n",
    "        # Train on mini-batches\n",
    "        for start in range(0, len(obs_buf), MINI_BATCH_SIZE):\n",
    "            end = start + MINI_BATCH_SIZE\n",
    "            batch_idx = indices[start:end]\n",
    "            \n",
    "            batch_obs = tf.constant(obs_buf[batch_idx])\n",
    "            batch_act = tf.constant(act_buf[batch_idx])\n",
    "            batch_adv = tf.constant(adv_buf[batch_idx])\n",
    "            batch_ret = tf.constant(ret_buf[batch_idx])\n",
    "            batch_logp = tf.constant(logp_buf[batch_idx])\n",
    "            batch_val = tf.constant(val_buf[batch_idx])\n",
    "            \n",
    "            # Perform gradient update\n",
    "            total_loss, policy_loss, value_loss, entropy = train_step(\n",
    "                model, optimizer, batch_obs, batch_act,\n",
    "                batch_adv, batch_ret, batch_logp, batch_val\n",
    "            )\n",
    "            \n",
    "            total_losses.append(total_loss.numpy())\n",
    "            policy_losses.append(policy_loss.numpy())\n",
    "            value_losses.append(value_loss.numpy())\n",
    "            entropies.append(entropy.numpy())\n",
    "    \n",
    "    # === 4. Logging ===\n",
    "    epoch_time = time.time() - epoch_start_time\n",
    "    \n",
    "    if (epoch + 1) % LOG_INTERVAL == 0:\n",
    "        print(f\"\\nEpoch {epoch + 1}/{TRAIN_EPOCHS} ({epoch_time:.1f}s)\")\n",
    "        print(f\"  Returns: {mean_return:.2f} | Lengths: {mean_length:.1f}\")\n",
    "        print(f\"  Policy Loss: {np.mean(policy_losses):.4f}\")\n",
    "        print(f\"  Value Loss: {np.mean(value_losses):.4f}\")\n",
    "        print(f\"  Entropy: {np.mean(entropies):.4f}\")\n",
    "        \n",
    "        # Periodic evaluation\n",
    "        if (epoch + 1) % (LOG_INTERVAL * 5) == 0:\n",
    "            eval_return, eval_std, eval_length = evaluate_policy(env, model, EVAL_EPISODES)\n",
    "            print(f\"  [EVAL] Return: {eval_return:.2f} Â± {eval_std:.2f} | Length: {eval_length:.1f}\")\n",
    "            training_stats['eval_return'].append(eval_return)\n",
    "            training_stats['eval_std'].append(eval_std)\n",
    "    \n",
    "    # Store metrics\n",
    "    training_stats['epoch'].append(epoch + 1)\n",
    "    training_stats['mean_return'].append(mean_return)\n",
    "    training_stats['mean_length'].append(mean_length)\n",
    "    training_stats['policy_loss'].append(np.mean(policy_losses))\n",
    "    training_stats['value_loss'].append(np.mean(value_losses))\n",
    "    training_stats['entropy'].append(np.mean(entropies))\n",
    "    \n",
    "    # === 5. Save checkpoint ===\n",
    "    if (epoch + 1) % SAVE_INTERVAL == 0:\n",
    "        checkpoint_path = f'checkpoints/model_ely_dec9_1AM_epoch_{epoch + 1}.h5'\n",
    "        model.save_weights(checkpoint_path)\n",
    "        print(f\"  [SAVED] Checkpoint: {checkpoint_path}\")\n",
    "\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f2499d55-efb1-4ad2-bdbc-a662990bf2da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized with 4,863,467 parameters\n",
      "Loaded model from checkpoints/model_epoch_75.h5\n",
      "  [EVAL] Return: -36.89 Â± 6.77 | Length: 12.2\n"
     ]
    }
   ],
   "source": [
    "#JUST FOR LOADING AND EVALUATING A MODEL\n",
    "\n",
    "env = Run3Env()\n",
    "model = PPOActorCritic(input_channels=FRAME_STACK, num_actions=NUM_ACTIONS)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE)\n",
    "buffer = PPOBuffer(\n",
    "    size=STEPS_PER_EPOCH,\n",
    "    obs_shape=(RESOLUTION, RESOLUTION, FRAME_STACK),\n",
    "    gamma=GAMMA,\n",
    "    lam=GAE_LAMBDA\n",
    ")\n",
    "\n",
    "# Build model by running a forward pass\n",
    "dummy_obs = tf.random.normal((1, RESOLUTION, RESOLUTION, FRAME_STACK))\n",
    "_ = model(dummy_obs)\n",
    "print(f\"Model initialized with {model.count_params():,} parameters\")\n",
    "\n",
    "model_path = 'checkpoints/model_epoch_75.h5'  # or whichever epoch you want\n",
    "model.load_weights(model_path)\n",
    "print(f\"Loaded model from {model_path}\")\n",
    "\n",
    "eval_return, eval_std, eval_length = evaluate_policy(env, model, EVAL_EPISODES)\n",
    "print(f\"  [EVAL] Return: {eval_return:.2f} Â± {eval_std:.2f} | Length: {eval_length:.1f}\")\n",
    "training_stats['eval_return'].append(eval_return)\n",
    "training_stats['eval_std'].append(eval_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d78a597-272a-4951-8f32-aff17cf1cabf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 (Run3 Project)",
   "language": "python",
   "name": "run3_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
