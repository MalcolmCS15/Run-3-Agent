{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0bb4b5f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All imports successful for Run3 project!\n",
      "TensorFlow version: 2.15.0\n",
      "NumPy version: 1.26.4\n",
      "OpenCV version: 4.10.0\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from collections import deque\n",
    "\n",
    "# -------- Image processing -----\n",
    "import pyautogui\n",
    "import numpy as np\n",
    "import cv2\n",
    "import mss\n",
    "\n",
    "# -------- TensorFlow / Keras ----\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model\n",
    "\n",
    "# -------- Misc / Debug ----------\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"All imports successful for Run3 project!\")\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "print(f\"OpenCV version: {cv2.__version__}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3e43e794",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Establish some variables and params for later\n",
    "\n",
    "#number of frames to feed model at a time. We input to the model the FRAME_STACK most recent frames\n",
    "FRAME_STACK = 4\n",
    "\n",
    "#variables for the location of the run 3 game on the screen. This is for Malcolms computer, if its diff for u make new vars\n",
    "TOP_X = 275\n",
    "TOP_Y = 195\n",
    "WIDTH = 725\n",
    "HEIGHT = 545\n",
    "\n",
    "GAMEOVER_X = 860\n",
    "GAMEOVER_Y = 435\n",
    "GAMEOVER_W = 70\n",
    "GAMEOVER_H = 45\n",
    "\n",
    "RUNWAY_X = 600\n",
    "RUNWAY_Y = 480\n",
    "RUNWAY_W = 135\n",
    "RUNWAY_H = 230\n",
    "\n",
    "#Which device is running the game. Add ur own if u wanna train. So we dont have to go all the way through everything and change\n",
    "MAC_LAPTOP = True \n",
    "MAC_MONITOR = False\n",
    "\n",
    "if MAC_LAPTOP: \n",
    "    TOP_X = 275\n",
    "    TOP_Y = 195\n",
    "    WIDTH = 725\n",
    "    HEIGHT = 545\n",
    "\n",
    "    GAMEOVER_X = 860\n",
    "    GAMEOVER_Y = 435\n",
    "    GAMEOVER_W = 70\n",
    "    GAMEOVER_H = 45\n",
    "\n",
    "    RUNWAY_X = 600\n",
    "    RUNWAY_Y = 480\n",
    "    RUNWAY_W = 135\n",
    "    RUNWAY_H = 230\n",
    "\n",
    "\n",
    "#resolution of the image were resizing to. This affects the input to our neural net directly.\n",
    "RESOLUTION = 96\n",
    "\n",
    "#number of actions the model can take. This is a super important thing to change if the model isnt training well. As of 12/5 were starting\n",
    "#with the model being able to take [no action, L_small, R_small, U_small, L_med, R_med ...etc.]\n",
    "NUM_ACTIONS = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e191780a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAGbCAYAAAAr/4yjAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAqvklEQVR4nO3dCXSU1fn48RfZIWAICfsWVokIFKEeRUSqdaOtbY91t2r3TW3Vtp7q0dZW29pqN2trtVrbqnXDUrStVRRXQEBkEwgQtoQAQSIJhFXyP897fnP/9z7MeycvmSSTme/nHA7zZJKZyTvLk/c+9z63TX19fX0AAEAQBMdwFAAACSQFAIBBUgAAGCQFAIBBUgAAGCQFAIBBUgAAGCQFAIBBUgAAGCQFoBX54Q9/GLRp06alHwayGEkhx/3lL38JP2QS/9q1axf0798/uOqqq4KKioqWfngAmlkbeh/lNkkKV199dXD77bcHxcXFwb59+4J58+aFXx8yZEiwfPnyoFOnTi39MPF/Dh06FP7jOUFTaddkt4xW5dxzzw0mTpwYXv7Sl74UFBYWBj//+c+Df/3rX8GFF17Y0g+v1ZHk2qFDh+CYY9J7Mi5ncvIPaCoMHyGpKVOmhP+vW7fOfO30008P/2ky1CRnFQkbNmwIh6J++ctfBn/605+CYcOGBR07dgwmTZoULFiwwHyfJBz5vqVLl5qvPfPMM+HXPvvZzzr3MXr06OCiiy4y8cMPPxx87GMfC3r16hXedklJSfCHP/zB+Zkrr7wyTG4HDx484jGfddZZwahRo7zPvvyuY8aMCRYtWhSccsopQefOncOzqT/+8Y/O982ZMyd8zP/4xz+CW265JRx+69KlS1BTUxNeP3/+/OCcc84Jjj322PDrU6dODd58803z808//XT486+++uoRj+H+++8Pr5MzNl9N4e9//3tw4oknho+xoKAguPjii4PNmzeb63/7298Gbdu2DT744APztbvvvju8reuvv9587cMPPwy6desWfP/73/ceG2QvkgKSkg920aNHj6M+Qo899ljwi1/8IvjqV78a/OQnPwlvUz7sEx/Sp556avih9Nprr5mfef3118O/rt944w3ztaqqqmDVqlXBaaedZr4mCWDw4MHBD37wg/DDbeDAgcE3vvGN4Pe//735niuuuCJ4//33gxdeeMF5XFu3bg1efvnl4PLLL0/5O1RXVwfnnXde+IF71113BQMGDAi+/vWvBw899NAR3/vjH/84eP7554Mbb7wxuPPOO8MzBbkfedySIG677bbw6/LBLAnt7bffDn9u+vTpQV5eXvDkk08ecZtPPPFEcPzxx4fJKcodd9wRfP7znw9GjBgR3HPPPcG3v/3tYPbs2eH9JpKAJPnDhw87xzVxrOX/hMWLFwe7d+92jjVyjNQUkLsefvhh2U+j/qWXXqqvqqqq37x5c/3TTz9dX1RUVN+xY8cwTpg6dWr4T7vyyivrBw8ebOL169eHt9mzZ8/6nTt3mq/PnDkz/PqsWbPM144//vj6Cy+80MQTJkyo/9znPhd+38qVK8OvzZgxI4yXLFlivq+uru6Ix3H22WfXDx061MQffvhh/YABA+ovuugi5/vuueee+jZt2tSXlZV5j438rnK/d999t/na/v3768ePH1/fq1ev+gMHDoRfe+WVV8Lvk/u2H9fhw4frR4wYET4uuWw/9uLi4vqPf/zj5muXXHJJeJuHDh0yX6usrKw/5phj6m+//Xbztdtuuy28r4QNGzbUt23btv6OO+5wHvuyZcvq27VrZ74ux6J79+713/ve98xjk+dHjrX8fG1trTk2cp/V1dXeY4PsxZkCQmeeeWZQVFQU/sV9wQUXBF27dg2Hd+Qv46Mlwz32mUZiSKqsrMz5WuIv1dra2mDJkiXBV77ylXDYJ/F1+T8/P9/5a1mGSRJ27doV7NixIxyWkduWWMhfwZdddln4e8htJzz66KPhcJAMBaUi4/dyppMgf/1LvH379nBYSQ9X2Y/r3XffDdasWRNceuml4RmLPEb5t2fPnuCMM84Iz5Dkr/fEsZLblKEoe1hJrreHzbQZM2aE3yN1n8Tty78+ffqEZw6vvPKKORbyOyfOylauXBk+pptuukkyTDB37lxzrOU4y/FGbiIpICTDLi+++GL4QSTDJfLBImP1jTFo0CAnTiQIGZKxk0JlZWWwdu3a4K233gqHk04++WQnWcj/kydPdoq2MiYviUySl3yASUKToSSRSApChlX27t0bPPvss2G8evXq8MNchpYaol+/fuF92EaOHOkMsSXoJCMJIZEs5PHZ/x588MFg//795rEmag4yXJQgl8ePH2/uLxm5D/lQlwSg70M++CXR2Mdafnc5HnJM+/btG0yYMCEYN26cOdYyvJRI3shNTGNA6KMf/aiZffTpT386HO+Xv3DlQ1TGu4V8YCfbvVWKk8lIYTMZ+zbkfoT8BSt/5cuHlHwIyweTFEdlfFvGuWXcPEGK3/KX9nHHHReOocvZjfwF/+9//zv41a9+Zf76FlKAlnqAFGIlQcj/8r1NMaPKPksQicchdRX5cE8mcWwlActxl+R13333Bdu2bQsTn9QgfOQ+5Hn5z3/+k/R4J24/caylniNnBZIEEh/+iQQsdRup35AUchtJAUeQD5ef/vSnwbRp04J77703HGJI/KVvD/0kbNy4sVFnE/JPPpTkthMfSFLolFkxTz31VJh07MLnrFmzwr+yZVjIPhtJDJVokgzktuSMRIrfUthtaAF9y5Yt4XCPfbZQWloa/m/PuEpGZl2J7t27h2c1qcgw0SOPPBIWieWvfEmevqGjxH3I98lZiu+MIpH4JSHKsZZ/3/3ud8Ovy7F94IEHwvtNxMhdDB8hcjqmfIj8+te/DufcJz6AEn9NJkgNwJ5eeTQkEcgsHZmNk0gK8pe1TI382c9+Fv4FLn/tJyT+IrbPOGQYRqapJnPJJZeEf01fd911YeJpyKyjBFkoJtNCEw4cOBDGMjxjP6Zk5Ho5ZjI1V854NPs4CkkcMp1Uho3knxz/VHUPmc0lx+NHP/rREWdxEkvdIEEWvMm04McffzzYtGmTc6YgQ0pyZiaPV4aVkLtICogkf0nKMIasbhZf+MIXwuGHs88+O6xByBRLme8vUyYbQz6U5ENK/vpPDCfJB50URuWv8pNOOin8CzdB7lPiT37yk+HjkEV28gEsaxaSkQ9wGbOXsw6pP8iZQkNJTUFu/9prrw3PmmTYSgrIMpzVvn17789KDURqB7JeQI6RrDGQv8jlfymKy/G0ye3Jh7w8TlnbkOosQciHuEz3lTMgOXYyVCXrKGSdgazD0IlSjrUMCUr94oQTTgi/JsdNvleONUNHICkgknxAJf7SlSEcWUD217/+NfyrXIZjZPjmb3/7W1gHaIzEB5HUCHr27HnE1/UHlXyAJRZ8yZoA+RCUGUtyJhBFhpCE1BLiFNBlmElqFQsXLgyTpHzAS3L48pe/3OAzLhnDl3qN/Nw111wTJlmZHfSd73zniO+XRJA4q2ho3UOG92TRnyQhOWOQYyLPjSTPT33qU873Jo6lJFy7cB91rJF76H2EnDBz5sywkCsF7YZ+8MkHuszCSqwmBnIBZwrICTJsM3ToUDM8BSA5Zh8hq0k/IumtJO0nfvOb37AXAZACSQFZTWYeyVz9L37xi2FvJAB+1BQAAAY1BQCAQVIAAKS/piBT/mx2zxa9daDMd7fpTpzSIdOW7t2rmordc0dIWwVfOwhZRBT1e8uCKd8xY/N2JNj7ISQ2PbLJQjnbzTffnLQdRzKy0jlZk78Eey+MZNfHee/qFdljx451YmmUaBs+fLgT68WE9vtRmi3aZD2HzW4cKGT9je+xZLPW8WkLAGgWJAUAgEFSAADEn5Jqb/gt7L1ehfSAt8kG5QmJxlsJdGFMPv4qG80k2A3gko0TS1trm67bIHvpFuG33nrrEe05bLJns83uL5Xo/GqT/SvsvbBt0qjPpleIS7NEW+/evZ3Yfl0nuu/abcp9dUr7cQnd10k3GLRbieu9JqSHle3222/3Xn+n2teisf2+MhlnCgAAg6QAADBICgCA+DUF2YHLJv3abXqjFdkbN9VevYje63jBggXOdfYOWuIzn/mMd3xVtoC06eeAdQ6ti2xulCD7Tthkj2rbk08+6cRRmw/ZTQNtt9xyi7ksu7/ZZFOjOK+zxpBd73w1B93LSjaEssl+3QmpuuPKvt+2Cy64wHsMZY8NWzZ9xnGmAAAwSAoAAJICAKARNYXzzz/fifXaA92/qLX0K8pU+mlZv369d852165dnXjIkCHevjF2L5fBgwc717HmIfM8++yzR+w3HdXHR/bPbmh9IrEXd9Qao9/97nex6hMtuc5H73ltvwfuvvtu5zq9T7ddz0vWH0rXXWSvcttpp50WZAs+uQEABkkBABC/dbZeOm+fYgqmOKaXPp56OEifxu/fv9/bumDWrFlObLcv6NOnj3PdQw895MQMJ7U8e4pyXV1do957ZWVlTrx79+7I6ZgFBQVBptLDnhdffHHk61gPv+ppvfoYtlGxbq29cuVKJ2b4CACQlRg+AgAYJAUAQPyagp7yiOalp/jm5eV5Y03XDWprayO3VLzkkku80/MmTpzYwEeNdLniiivM5UcffdS5bsaMGd6xdt0uQm81qac/T5o0qVW0b9C1kIULF0bWwlK9P1Lp3LmzE+fn5wfZijMFAIBBUgAAGCQFAED8mgJaNz3v2m55PHnyZOe65557zolLS0udePz48U7crh0vo6Y2evToyLb1eovMpUuXep/7M844w7uF5ogRIyJ/tiXptTj3339/ZCsQcd1115nL/fr1i7XdcJlay1FcXOzE+j2TTThTAAAYJAUAgEFSAAAYDAZnicOHD3uv97Uy13Ou9W1t3brV23qZmkLzGjdunDdurfR6iUWLFjnxgw8+6F2X8K1vfcuJL7/88sjXv26Vrbcwffnll71bf+qtArIJZwoAAIOkAAAwSAoAgPg1BT2PN5t7f7QGe/fudeJ58+Y58b59+5x45MiRkfOud+zY4a0RDB8+3LuVIdBQdh+mJUuWONc99dRT3nUHen3Fn//85wbXVvTn17333uvE9913nxPfeOONTnzNNdcEuYIzBQCAQVIAABgkBQBA/JrChg0bnHjMmDFOzFz1pqVrBO+8844TV1dXO/GECROcuLy83Im3bNliLldVVUX2vklWU/CteUBu02sNNm7cGLke4LHHHvPum/zMM894P3M0vX5m7ty5kTWD5cuXO/H111/vxDfccIMTZ1IPqKbGuxsAYJAUAAAGSQEAEL+msHnzZidu3769dxy6Q4cODb1pNKB3/KpVq5x427ZtTvzNb37Tic877zxvr5d169aZywcOHHCuO+GEE5yYGgKi6D5Zeu3BrbfeGlnb0td94hOf8H6G6L2m9b4RDz/8sBO/8cYb5vKUKVOc62bOnOnEQ4cOzdkagsaZAgDAICkAAOIPH+lTuyeeeMKJa2pqnPikk04ylxl+aJg9e/aYy6+//rr3VPqmm25y4lNOOcWJ27Zt643t7R2Bo2VPbRaXXnqpdxvLxx9/PHLIWb9G9TRqvf2m3pZUD3s+9NBD5vLYsWO994X/jzMFAIBBUgAAGCQFAED8msJll13mrSH873//i2xj26VLl4beTU7ZtWuXE7/yyivmcklJiXPdtdde690OkLoNmoOeFqrbR+jPha997WuRLdz1a1b/7JlnnultFz9jxgxvGwy7DpfLU0zj4kwBAGCQFAAABkkBABC/pqC3vtPLxDt16uTEnTt3jmynq7fGW716tbdNdGFhoRMXFRU58bHHHpu2sfVUj7WysjKyXbU+BqNGjXLiHj16RB4j0bNnT3N506ZNkW2AxfTp0504Ly8vyW8DpJdul6K3gdXrAXRtzH5/6vYqN998c+T7Wvzzn//0ttpGenCmAAAwSAoAAIOkAACIX1NYuHChEw8cONDbyvnNN99scL+UVCZOnOhtK20/Nr0ln441XYPQayr69u0b2TPotddec6577733nLiiosKJe/fu7W0/vmPHjsh6wyOPPOIdT7XXhQAtRW/L6+sxpGuJuj6h+yZRQ2genCkAAAySAgDAICkAAOLXFHTfkSuvvNI7dm/PQa6rq/OOpa9du9Y7Nn/hhRc6cf/+/SPvy96TIFn9Qa9D0GOg3bp1c+KOHTtG9ivSawn09+o9DrZv3+6tX0yePDmy/vD0009H9kkSbKGJ5qDfL1dccYUT33XXXU581VVXRfY+Wr58uXfPkMsvv7zRjxfxcaYAADBICgAAg6QAAIhfU9Dz+bt27ertUxJnH4H58+d7+6vo+9a90e2xfD2un252fyP9O+uage4Do9ce+OhjMGTIEO+6kd27dztx9+7dG3xfQEPp9+KECROceNq0aU785JNPOrG9tmfQoEHOdVdffbW3bxKaB2cKAACDpAAAMEgKAID4NQXdw+Sll17yzu+3Y11/2LlzpxOXl5c78RlnnJGx4+P2PO1+/fp5+z29++673t4tev2GvRZk/fr13j4xp512mhOznwKawuHDh534rbfecuLrrrvOiYcPH+7E119/vRPbnwW1tbXe237xxRe9+0Hrmh37MKcHZwoAAIOkAAAw2tTrvg8RSktLnVi3jdbDSfZWlfbSdpGfn++d1nbeeec5cVNPMz1aejvB2bNne4+RPhVfuXJl5JRV3Tb45JNPduKzzz7buxUokA4bNmxw4ilTpnjfm7plTRx6WnWvXr2cWH+OzJkzx/u5gqPDmQIAwCApAAAMkgIAIP6UVD2ep+NRo0ZFTqE8//zzneuKioqCbKBb/Z577rneWJdv9Babdkvw008/3dtuHGgOulalW1Po6eT2lrKisLCwwfelt/TVU0z1fes23kgPzhQAAAZJAQBgkBQAAPHXKaSib8aOdbtdJF+3YI+hsmQfmUiP+99www1OvGTJEifu06ePExcUFES2mq+qqvK2crnzzjudmHUJTYNPawCAQVIAABgkBQBA+msKAHLP/v37nXjNmjVOXFFR4cQHDx6M7Jukt5zVMWt1mgdnCgAAg6QAADBICgAAg5oCAMDgTAEAYJAUAAAGSQEAYJAUAAAGSQEAYJAUAAAGSQEAYJAUAAAGSQEAYJAUAAAGSQEAYJAUAAAGSQEAYJAUAAAGSQEAYJAUAAAGSQEAYJAUAAAGSQEAYJAUAAAGSQEAYJAUAAAGSQEAYJAUAAAGSQEAYJAUAAAGSQEAYJAUAAAGSQEAYJAUAAAGSQEAYJAUAAAGSQEAYJAUAAAGSQEAYJAUAAAGSQEAYJAUAAAGSQEAYJAUAAAGSQEAYJAUAAAGSQEAYJAUAAAGSQEAYJAUAAAGSQEAYJAUAAAGSQEAYLQLGqi8vLyh34omcMwxbv5u06aNN46jvr7ee3067yub2MdNH0MdHz58uNkeF7L7ve+T6nU2YMCAIBXOFAAABkkBAGCQFAAARpv6VAPK/+ess85qyLchTfS4fdeuXZ24V69eTlxQUODE7du3d+IDBw448f79+83lDz/80LkuPz/fiYcNG+bEnTp18j7WbKXfKnV1deZyaWmpc93WrVu98aFDh5rkMSI92rZt68QdOnRw4oMHDzqx/R5q4Edqg+Xl5TnxcccdZy7v27fPuW7VqlXe32PWrFkp748zBQCAQVIAABgkBQBA/JqCHjfWc2f12FW7du0i587q8TjmcKdmH0/RpUsXb81B03UD++cLCwud66ZMmeLEw4cP9z7Xucp+3W7fvt25bsGCBU68bNkyJ66oqPA+P2hZPXv2dOKxY8c68ZYtW5x43bp1TVYv0vXB7t27R75uampqvLfVkNcZZwoAAIOkAACIP3ykhwzsUxhRUlLixOPGjUt6aiUWLlzoxLt27crYU2k9bGYvE9fX6VPKTJp2qE9Bhw4dmnSKmzjzzDO9P4sj6bdRWVmZE8+ePdt7vX4PpHtaI+Jpk2K4vCXbmNifxXpqeufOnb2fSXv37k15+5wpAAAMkgIAwCApAADit85ONeamx53tKY8dO3Y86lawmcZe7p5J7R30Y9FTWHUNyF46r9vp6p9F/OOvpzTqKcR67Le2tjZj62q5qF7VDDL1+dCfu+loQdN6P50BAGlHUgAAGCQFAIDR4MFjPQ9Xz6ueP3++Ey9ZsqRBbZszebwu2diiXnPho8fzdG1Fj//Z84/1MdLH0Lf0PVnbC10nsH9ej3dnUq2ktdKtlouKirw1BP3+0tf7Wp0jt3xoPf+bNm1K++1zpgAAMEgKAACDpAAAMI56QroeA9Xbwuk4U+jx8t69ezuxnrO/Zs0aby3Ft/5Cb5Gpb3v06NFObI/t6944VVVV3hqDHoOurKz01hTseoa9rWSyOgo1hvh0nUa3Ix8zZoy3R82GDRucuLy8PHJrz927dzsxNYfc0UZ9nvXo0cOJ+/XrF/s2OVMAABgkBQCAQVIAABjtcn0MTo/96vnkGzdubPBt63UHul4xcOBA7xZ/9loD3Sf95ZdfduIdO3Y4sd4OUtd89Lx5exxa1y9GjhzpXV+B+HSvIx337dvXiY8//vjI7TsXLVrkXTuj6xPUGHJHR/Ve1T24GoIzBQCAQVIAABgkBQBA/D2amauemh631+PEeg5xnz59IscDdc1ArzvQayB0rPfBrq6uduJu3bqZy4MGDXKuO/XUU51Y7+Gsayc4cm2HXjuwfPnyyP0sGlLHsW9f97t56623nHj16tVOvG3btsjbQm6pb8Bzz5kCAMAgKQAADJICACB31yk0pYMHD0bOLU9WJ9D9bey1Bfq2dK8j3QtJj0HrXki+Me/Nmzc71y1YsMDbx0r37dF7N+RK/cl+vvRzu3TpUu9zrdfD6B41vpqCfj5S7b1BDQFxcKYAADBICgCA3Bk+0u2s9al0Ok+t9W0dOnTIGzeGHh7ScZyhj5qaGm+78D179njbh+uWDHpoJFvaZOjn154mPG/ePOe69evXe4+Zvi09hKfbr9jDU7rNhR6m1NNh9W3prVv1Y7FfD3qoqrHvF7uF+9ChQ72Pc+XKld5hMjQNzhQAAAZJAQBgkBQAANlbU9DTI3WLhg8++MA7VTBOm+H27dt7t7zUY6C6nXWm1l107UO3D9fHUF+vp1cOHz48spWvHt/Wx1A/tsZI91RZu62Jfm71MdTHLNVj0zUGu6agW2Pv3LnTewx1C41zzz3XifVj/+9//xvZMqOx2+zaNQk9dVY/bqbStgzOFAAABkkBAGCQFAAA2ds6W49LHnvssU6sxzH1nO5Uh8Me49b1Cj1ff86cOd7WFJli8ODBTnzSSSc58dtvv+3EunWzPuZ6vrm9tahuH66/V8d2i+9kbbv161I/v76xdb1dalz2a2f27NneOfb6mGl6LYf+Pe3tO6dPn+792eeee857X8OGDfPWFOw6gt7mNZ1rbdD8aJ0NAIiF4SMAgEFSAABk7zoFPeb5/vvvp/X27fFX3SNIr3lINadbz8G3x8fjrJfQP5ss9o0l6u0a9fi4buOttx1NVVOwj9nWrVu98/d1TUAfIz1+np+fH7nF6ejRo71rIlLRz4GuP61atSpyXYF+3aXqubV3717vY7HrHwMGDIh1TPTrtLy8vMG/d3OuFdD1Jl3r0nUZvcVsOh9rntouVW9Zq+/brr3Efe9mGs4UAAAGSQEAYJAUAADZW1NoLD2Grfsb2TULPdau41T0Ogd73HjhwoWx9ksoLCx04v79+zux7pdj/x66V5H+WX1M9HoLPdauY/u+dT+oVOOv+r51b6uCggInHjduXOTx1c+lHsfX48S6p5OO7RqSrsukqifpx5JqvYV9Xw888IBzXdu2bb29kPRjydQx71S1KX19HPr46mOW6vrO1jqRZK/xbMKZAgDAICkAAAySAgAge3sfNZbdp0dMmzbNiZcvX24ur1ixolH3pesA9ni5vf9vqp4+DekZpH/erl+MHz/e2/tIW7p0qRPPnz/fO/au93iOQ/cA0vv66rUIdl+furq6yD0JktVZ9PV6rYGu69hj9an2ytC/hz7mukfXm2++GXkM9XOra0L2Wg1RVlbmrQmlWiPRUuKstUlFH/+xY8d66xWLFy924nTvVd1S6H0EAIiF4SMAgEFSAAAY1BRizpW259nrOfdx+eo06R6z1POu7XqGXpcwZswY72PR/Yt03x9dU2jMmLV+PvS6BN2jxh7b13UU/Th0zUH3zUrnfH79XOsxbv386MdmPwe6J9DUqVOd+OSTT3bimTNnOrFeAxNnn49UtcVMHWtPdfxT/V4F6nWn62S7du1qsr3Y01lboaYAAIiF4SMAgMHwUQvSLZDtaYnr1q2L1TYhLrt9RKqtIHU8ceJE7/VNuQ1pnKnRmTqU0Vj6eOtW2Xp6qz7+emqtrz2LbscxatQo78/qNt3pHkppLt1Vm/URI0Z4j2lFRUXa2t7r+y4uLnZiu6WKbq+S6ngzfAQAiIXhIwCAQVIAABi0zm5Buk5gT0ts6rFY+/b1VE0d62mhS5Ys8V6fqs13Y2RrnaAxrxvdKltPZ0019dZHvw51y2h9W9ny/NTU1DjxokWLmu2+9THVj8WeCt8Ux5szBQCAQVIAABgkBQCAwToFoJXR89p12wu9DemCBQu8LcF9dPsN3ZZbz8nX8+azpcaQLVinAACIheEjAIBBUgAAGKxTaEYt2XbY7nWk76s1j/vqY2rH+vdqzb+n/fwNGTLE25/o1Vdf9Y7765/XysvLI2sKJSUl3jUtuidQOtuPo3lwpgAAMEgKAACDpAAAMKgpNCG9T4Huya63iywrKzuq/jTJxn579OjhxCeccIITb9++3VwuLS1tcH/9lqbHz4cNG+bEvXv3juzR9MEHHwTZQNeHdF1FP3/6taG3MNW1Fvv29ZazL7744lE+arQWnCkAAAySAgDAICkAAAxqCk1I1wUqKyu9c7gbs4eCPZaebC9dvceB3aOmNc0lT9Vrx/499Rz61sx+baxduzbWz3bo0MGJi4qKIm872f7gyC2cKQAADJICAMAgKQAADPZTyBJ6LrreN1nXN1pTHQGNo2sKuveRrils3LixVaxZQXzspwAAiIXhIwCAwZTUNNLtBnQ7An2ans5Wzno4iOEhHG2bDOQ2zhQAAAZJAQBgkBQAAAZTUtOoV69eTjxlyhQnXr16tRO/9957aWtzgdzRuXNnb01At/dIVbvSLd7t9uR1dXXOdbxGWzempAIAYmH4CABgkBQAAAY1hTTSrSW6du3qxHprw3379qXz7pEjbUwmTZrkrQnMnTvXu+2rVlJS4sT9+/c3l+fPn+9cV1NTE+NRI9NQUwAAxMLwEQDAICkAAOLXFPS4ZWFhoRPn5+c78YYNGyLnOqPp5eXlOfGYMWOcuLq6OnL7Rd1mG+mn1xb069fPiYuLi524tLQ06XOXTNx217rtut0bSb8W0tmvC82PmgIAIBaGjwAABkkBABB/P4Vu3bp559jv2rXLiRmXbln6+O/YscOJ9+zZk7ZxYj0mrWP7sdA7Jzndr2j79u2R16d7i0z24oCNMwUAgEFSAAAYJAUAQPx1CrqHu+7jw/zl3N3jd9CgQU48YMCAyH0j9Bx7XjdA82GdAgAgFoaPAAAGSQEAYLCfAtK+j4Rep2DPq9frFHr27OnEPXr0cOJt27Y5cW1tbdAa6iy6V5he56PXkezevduJ9VoEai9IB2oKAIBYGD4CAMRvcwFE0UMhcVqc6GGXVC2mW0ur8pEjRzrx9OnTvcNiL730khNv3LjRidPd2gLxXpft27f3tgbJprY+nCkAAAySAgDAICkAAAxqCmjyKardu3ePbLmuW3rruLVMxdRj/vr3eOedd5y4pqbG23qeFuMtK19tL/yRj3zEicvLy53Y3tK2tdcXOFMAABgkBQCAQVIAABi0uUDa6dYVU6ZMMZfLysqc61asWOGd/50t89x16w9dK9G/d6bUUvTvoR9XpjzOpv69O3To0OB1Cpl8TGhzAQCIheEjAIBBUgAAGNQUkHa6X5E9nq7n3zMfP/MUFBSYy+PGjXOuW7NmjRNXVFQ4cSaPpyOgpgAAiIfhIwCAQVIAABj0PkLa6XHl1t4LpinmvXfq1Mm7jmHPnj0tVnvZv3+/uVxZWel9XMg+nCkAAAySAgDAICkAAAzWKQDNQNcQ9Px/e88JMXfuXCfevXt3Ez465Ir6Bqwj4UwBAGCQFAAABsNHzdjuIZVsaRHQpUsXJx4yZIi5vHPnTue6bdu2ZeUxiNP6I9mUVb29Z7Yel8bQx6xPnz5O3LdvX3N5/fr13u1P9fE93IxTgJsTw0cAgFgYPgIAGCQFAIBBm4tG0Fv0FRYWOvHw4cO9Y+1btmxx4k2bNpnLNTU1GTPGqcfD9fRKfb2ODxw4kHXbbcZF64/mP6b79u2LfK9OnDjRW+NZvHixE+/duzdoKfqxdezYMfIY2L9zsusbgjMFAIBBUgAAGCQFAIDBOoWY7PHyHj16ONdNmjTJiS+99FLvPOo5c+Y48fPPP28ur169OrKdcXOzxzDF+PHjvde/++67TqzrI0BLj8vr965e8/D+++87cUvWwvLz8yNbpOhW5kuXLo2s5wnWKQAAYmH4CABgkBQAAAY1hUbQc5979uzpxCNGjMjKdQqdO3d24oKCAu/vWVFRYS6znePRbdeZl5cXWV+qq6vz9k1C9r42DqvPBf3a0DUEagoAgFgYPgIAGCQFAIBB76NG0HOAKysrnXjr1q3esfmjGe9rDvpxtmvXzjtmrWP9/XpMFEceYz0X/cQTT3Ti008/3Vx+7733nOtef/31yBpOLvebainHqNe7fj/o50PHqX7erhs0xXPLuxUAYJAUAAAGSQEAYFBTaEKZWjNIpVu3bk48evRoJ66urnbisrIy777LSF1T0Gs9Bg0aFLmmZePGjd51Cq3ldZatioqKnHjUqFGR65GSPZ/6tVBSUhL58/q20rGeiTMFAIBBUgAAGCQFAIBB76Mc6cukxzntvVx1jUCPd+v9EvTc6KPp2Q7/86V7H9nHXB9v/Xy0ZJ8sBEesK9DPpX7+dKx/Xr//7HVB+mdTofcRACAWho8AAJk9fKTvS2+lpx8yy/iPpNtbDx061Int1ty6hXeuHk/9utPtBvTrjmEatDYMHwEAYmH4CABgkBQAAJldU9DLvCdPnuzEVVVVTjxv3rxmeVytme/5y9UppHqqX9++fZ24uLjYidetW+fE5eXl5jL1BbQG1BQAALEwfAQAMEgKAIDMrinoZd55eXlOfOjQISfevXt35G3pNQ66LbS+Xrd8YKw4e+jX1fjx45144MCBTrx48WIn1us54rYYyJTfu7Cw0In1R8COHTuCXF+zkq2oKQAAYmH4CABgkBQAAJldU2jKlsRDhgxx4vbt2ztxaWlpZJtaZBf93OteR/q5b631Jd26edy4cU6s6wbLli0zl/fv3x9kqlSfSZmy/qZNBj1OagoAgFgYPgIAGCQFAEDu1BQyeXwPzftc6xqCfq71+pdsfS201veAXlM0atQo7x4iq1evbtBapnS/tnr27Olcp2N7LxOxfft2J9Z1nHQ+H9QUAACxMHwEADBICgAAw22KkgMydbwUzT8/X/cuWrFihRNn8hz9XHwP6HUi9n4WydaZ7Nu3r8keSxtVU+jevXvk/i9Tp0514qVLlzrxCy+84O2xpWtdTY0zBQCAQVIAABgkBQBA7q5TQO5gnQJa4rVVqParKCoqcuJdu3Y58bZt27y1ENYpAABaDMNHAICmHz6yv19PDdSnV7q99c6dO514z549DW5H0Fqn2wFNRb+/RowY4W2dXVZW1uq2HM1kbTKorQhtLgAAsTB8BAAwSAoAgKZvc2FP0Ro4cKBz3fTp05140KBBTvz22287cXV1tRNv3brVidevXx/ZIlePlwK5Rr8HqqqqYn1/a2W32tZttfVWq7p2Ut/M7aozCWcKAACDpAAAMEgKAICmX6dgt7HNy8vz1hCKi4udePTo0U58zjnnOPHGjRud+P777zeXly1b5l3jkMm6du1qLg8YMMBbR9Fb+rW2cUsgLv0ZpLe5bNeuXWSr7ZKSEu/7qbS0NPJnswnrFAAAsTB8BAAwSAoAgKZfp2CPyenx75UrV3q3n9NrDbp16+btjWSvY2jureuaqqag+9Podrq1tbVOTE0B2U5vt6l7qOkea2vXrjWXX331Ve9tt9b3zzHqmGhHUxvhTAEAYJAUAAAGSQEAkFnbcepxsY4dOzqxXueg6wZ2DcK310Jroo93a/090Lrp16Eet9evS91TyO6Bpt+f6a7/5cp7pr11TIcNG+Zcl5+f78QrVqxwYl3fTYYzBQCAQVIAABgkBQBAZtUUAGQmXUOYNm2ad/3MmjVrnFivt7HXDpSXlzvXpfoo0p9Bep2Crl/s2LEjK/eabmMdB71PhO7/lGp/+2Q4UwAAGCQFAIBBUgAAGNQUADR4HF+vIdJ1AD1mrce47evj7gVt77ksxowZE9k7TCxfvjzW/PxcUN+AEjJnCgAAg6QAADAYPgLQKqWaJp+tbS4ag+EjAEAsDB8BAAySAgCg6bfjbAw9jS1O62wAuYGaQdPgTAEAYJAUAAAGSQEAkNk1Bd2uV285V1tb68SlpaXN8rgANB/dUqN///7ettBVVVVOfPjw4SZ8dNmLMwUAgEFSAAAYJAUAQPyaAnOCASD7caYAADBICgAAg6QAADBICgAAg6QAADBICgAAg6QAADBICgAAg6QAAAgS/h+nYAYDewlHWwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def preprocess_frame(image, resize=(RESOLUTION, RESOLUTION), gray=True):\n",
    "    \"\"\"\n",
    "    Captures a screenshot of the given region, converts to grayscale, resizes.\n",
    "    Returns numpy array of shape (resize[1], resize[0]).\n",
    "    \"\"\"\n",
    "    if gray:\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Resize deterministically\n",
    "    small = cv2.resize(image, resize, interpolation=cv2.INTER_AREA)\n",
    "    \n",
    "    return small\n",
    "\n",
    "def stack_frames(frames, new_frame, stack_size=FRAME_STACK):\n",
    "    \"\"\"\n",
    "    Maintains a stack of frames to capture motion.\n",
    "    frames: deque of previous frames\n",
    "    new_frame: newest preprocessed frame\n",
    "    Returns stack of frames\n",
    "    \"\"\"\n",
    "    if len(frames) == 0:\n",
    "        # Initialize with repeated frame\n",
    "        for _ in range(stack_size):\n",
    "            frames.append(new_frame)\n",
    "    else:\n",
    "        frames.append(new_frame)\n",
    "        if len(frames) > stack_size:\n",
    "            frames.popleft()\n",
    "    return np.stack(frames, axis=0)\n",
    "\n",
    "#TEST to see if screen grab is working\n",
    "\n",
    "time.sleep(3)\n",
    "\n",
    "sct = mss.mss()\n",
    "monitor = {\n",
    "    \"top\": TOP_Y,\n",
    "    \"left\": TOP_X,\n",
    "    \"width\": WIDTH,\n",
    "    \"height\": HEIGHT\n",
    "}\n",
    "\n",
    "runway = {\n",
    "    \"top\": RUNWAY_Y,\n",
    "    \"left\": RUNWAY_X,\n",
    "    \"width\": RUNWAY_W,\n",
    "    \"height\": RUNWAY_H\n",
    "}\n",
    "screenshot = np.array(sct.grab(monitor))\n",
    "img = cv2.cvtColor(np.array(screenshot), cv2.COLOR_BGRA2BGR)\n",
    "processed = preprocess_frame(img)\n",
    "plt.imshow(processed, cmap=\"gray\")\n",
    "plt.title(\"Preprocessed frame (grayscale + resized)\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "\n",
    "screenshot = np.array(sct.grab(runway))\n",
    "img = cv2.cvtColor(np.array(screenshot), cv2.COLOR_BGRA2BGR)\n",
    "processed = preprocess_frame(img)\n",
    "plt.imshow(processed, cmap=\"gray\")\n",
    "plt.title(\"Runway preview\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b158ff17",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PPOActorCritic(tf.keras.Model):\n",
    "    def __init__(self, input_channels=FRAME_STACK, num_actions=NUM_ACTIONS):\n",
    "        super(PPOActorCritic, self).__init__()\n",
    "\n",
    "        # TensorFlow expects channels-last â†’ (RESOLUTION, RESOLUTION, C)\n",
    "        self.input_channels = input_channels\n",
    "        self.num_actions = num_actions\n",
    "        \n",
    "        # ---------- CNN Backbone ----------\n",
    "        self.conv1 = layers.Conv2D(32, kernel_size=8, strides=4, activation='relu')\n",
    "        self.conv2 = layers.Conv2D(64, kernel_size=4, strides=2, activation='relu')\n",
    "        self.conv3 = layers.Conv2D(64, kernel_size=3, strides=1, activation='relu')\n",
    "\n",
    "        #max pool? think about max pool if we use a larger resolution. But these convs also scale down.\n",
    "\n",
    "        # compute flatten size\n",
    "        self._conv_out_size = self._get_conv_out((RESOLUTION, RESOLUTION, input_channels))\n",
    "\n",
    "        # ---------- Shared Fully Connected ----------\n",
    "        self.fc = layers.Dense(512, activation='relu')\n",
    "\n",
    "        # ---------- Actor Head ----------\n",
    "        self.actor_fc1 = layers.Dense(64, activation='relu')\n",
    "        self.actor_logits = layers.Dense(num_actions, activation=None)\n",
    "\n",
    "        # ---------- Critic Head ----------\n",
    "        self.critic_fc1 = layers.Dense(64, activation='relu')\n",
    "        self.critic_value = layers.Dense(1, activation=None)\n",
    "\n",
    "    # -------------------------------------------------\n",
    "    # Compute conv output size by running dummy tensor. This saves us work if we change the CNN structure\n",
    "    # -------------------------------------------------\n",
    "    def _get_conv_out(self, shape):\n",
    "        dummy = tf.zeros((1, *shape), dtype=tf.float32)\n",
    "        x = self.conv1(dummy)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        return int(np.prod(x.shape[1:]))\n",
    "\n",
    "    # -------------------------------------------------\n",
    "    # Forward pass\n",
    "    # -------------------------------------------------\n",
    "    def call(self, x):\n",
    "        \"\"\"\n",
    "        x expected as (batch, RESOLUTION, RESOLUTION, 4)\n",
    "        \"\"\"\n",
    "        x = tf.cast(x, tf.float32) / 255.0 #normalize to [0,1]\n",
    "\n",
    "        # CNN backbone\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "\n",
    "        # Flatten\n",
    "        x = tf.reshape(x, (x.shape[0], -1))\n",
    "\n",
    "        # Shared FC\n",
    "        x = self.fc(x)\n",
    "\n",
    "        # ---- Actor ----\n",
    "        a = self.actor_fc1(x)\n",
    "        logits = self.actor_logits(a)\n",
    "\n",
    "        # ---- Critic ----\n",
    "        c = self.critic_fc1(x)\n",
    "        value = self.critic_value(c)\n",
    "\n",
    "        return logits, value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "026a525c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Run3Env:\n",
    "    def __init__(self, region=(TOP_X, TOP_Y, WIDTH, HEIGHT), frame_stack=FRAME_STACK):\n",
    "        self.region = region\n",
    "        self.frame_stack = frame_stack #integer, not the actual stack. Do we need instance var?\n",
    "        self.frames = deque(maxlen=frame_stack)\n",
    "\n",
    "        self.sct = mss.mss()\n",
    "        self.monitor = {\n",
    "            \"top\": region[1],      # TOP_Y\n",
    "            \"left\": region[0],     # TOP_X\n",
    "            \"width\": region[2],    # WIDTH\n",
    "            \"height\": region[3]    # HEIGHT\n",
    "        }\n",
    "\n",
    "    # -------------------------\n",
    "    # Reset environment\n",
    "    # -------------------------\n",
    "    def reset(self):\n",
    "        # Click to restart game. 900,650 is just off the screen a bit, click twice to bypass the \"continue\" and \"score\". \n",
    "        #we can also press a button to make it better for everyones computer\n",
    "        time.sleep(.7)\n",
    "        pyautogui.click(900, 650)\n",
    "        time.sleep(.7)\n",
    "        pyautogui.click(900, 650)\n",
    "        self.frames.clear()\n",
    "\n",
    "        # Get initial observation\n",
    "        raw = self.capture_raw()\n",
    "        processed = preprocess_frame(raw) #function defined at the top\n",
    "        stacked = stack_frames(self.frames, processed)\n",
    "        return np.transpose(stacked, (1, 2, 0))  # (RESOLUTION, RESOLUTION, FRAME_STACK). \n",
    "\n",
    "    # -------------------------\n",
    "    # Capture raw screenshot\n",
    "    # -------------------------\n",
    "    def capture_raw(self):\n",
    "        screenshot = np.array(self.sct.grab(self.monitor))\n",
    "        # mss returns BGRA, convert to BGR. Also mss is much faster than pyautogui so we use it for more fps.\n",
    "        img = cv2.cvtColor(screenshot, cv2.COLOR_BGRA2BGR)\n",
    "        return img\n",
    "\n",
    "    # -------------------------\n",
    "    # Detect game over\n",
    "    # -------------------------\n",
    "    def game_over(self, raw_frame): #FIX\n",
    "        \"\"\"Check if dialog region is white\"\"\"\n",
    "        # Extract region. Note hard coded values are for macs laptop, its a region of the screen where its all white on game over.\n",
    "        tlx = GAMEOVER_X - TOP_X\n",
    "        tly = GAMEOVER_Y - TOP_Y\n",
    "        w = GAMEOVER_W\n",
    "        h = GAMEOVER_H\n",
    "        roi = raw_frame[tly:tly+h, tlx:tlx+w]\n",
    "        \n",
    "        # Check if white directly on BGR image\n",
    "        mean_val = roi.mean()  # Average across all pixels AND all channels\n",
    "        \n",
    "        # If all channels are ~255, mean will be ~255\n",
    "        return mean_val > 250\n",
    "\n",
    "    def runway_reward(self, raw_frame):\n",
    "        tlx = RUNWAY_X - TOP_X\n",
    "        tly = RUNWAY_Y - TOP_Y\n",
    "        w = RUNWAY_W\n",
    "        h = RUNWAY_H\n",
    "        roi = raw_frame[tly:tly+h, tlx:tlx+w]\n",
    "\n",
    "        if len(roi.shape) == 3: #grayscale\n",
    "            roi_gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
    "        else:\n",
    "            roi_gray = roi\n",
    "        \n",
    "        platform_pixels = np.sum(roi_gray > 30)\n",
    "        total_pixels = roi_gray.size\n",
    "        platform_ratio = platform_pixels / total_pixels\n",
    "        \n",
    "        return platform_ratio #small reward based on % of runway occupied.\n",
    "\n",
    "    # -------------------------\n",
    "    # Take one step in environment \n",
    "    # -------------------------\n",
    "    def step(self, action): #NOT FINISHED DONT TOUCH\n",
    "        # step_start = time.time()\n",
    "        self._execute_action(action)\n",
    "\n",
    "        # Capture new frame\n",
    "        raw = self.capture_raw()\n",
    "\n",
    "        done = self.game_over(raw) #Boolean var\n",
    "\n",
    "        platform_score = self.runway_reward(raw)\n",
    "        # Reward logic\n",
    "        if done:\n",
    "            reward = -10\n",
    "        else:\n",
    "            reward = 0.1 + 2.0 * platform_score # small survival reward + a small alignment reward\n",
    "            if action == 0:\n",
    "                reward -= 0.05\n",
    "        # Preprocess\n",
    "        processed = preprocess_frame(raw)\n",
    "        stacked = stack_frames(self.frames, processed)\n",
    "        \n",
    "        state = np.transpose(stacked, (1, 2, 0))  # (REOSLUTION,RESOLUTION,STACK_FRAMES)\n",
    "\n",
    "        # TARGET_TIMESTEP = 0.33 \n",
    "        # elapsed = time.time() - step_start\n",
    "        # if elapsed < TARGET_TIMESTEP:\n",
    "        #     time.sleep(TARGET_TIMESTEP - elapsed)\n",
    "\n",
    "        return state, reward, done, {}\n",
    "\n",
    "    def _execute_action(self, action):\n",
    "        \"\"\"Execute action with proper hold durations\"\"\"\n",
    "        # Map actions to (key, duration_seconds)\n",
    "        action_config = {\n",
    "            0: (None, 0),           # No action\n",
    "            1: ('left', 0.05),       # Left short - 100ms\n",
    "            2: ('right', 0.05),      # Right short\n",
    "            3: ('up', 0.05),         # Up short (jump)\n",
    "            4: ('left', 0.1),      # Left medium - 250ms\n",
    "            5: ('right', 0.1),     # Right medium\n",
    "            6: ('up', 0.1),        # Up medium\n",
    "            7: ('left', 0.25),       # Left long - 500ms\n",
    "            8: ('right', 0.25),      # Right long\n",
    "            9: ('up', 0.25),         # Up long\n",
    "        }\n",
    "        \n",
    "        key, duration = action_config[action]\n",
    "        \n",
    "        if key is not None:\n",
    "            pyautogui.keyDown(key)\n",
    "            time.sleep(duration)\n",
    "            pyautogui.keyUp(key)\n",
    "        time.sleep(0.25-duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4956b50f-186c-4637-9921-97c2687ae8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #JUST FOR TESTING THINGS WORK WHEN RUNNING THE GAME.\n",
    "# sct = mss.mss()\n",
    "# monitor = {\n",
    "#     \"top\": TOP_Y,\n",
    "#     \"left\": TOP_X,\n",
    "#     \"width\": WIDTH,\n",
    "#     \"height\": HEIGHT\n",
    "# }\n",
    "# num_g_over = 0\n",
    "\n",
    "# def test_game_over(raw_frame):\n",
    "#     \"\"\"Check if dialog region is white\"\"\"\n",
    "#     # Extract region\n",
    "#     tlx = 860 - TOP_X\n",
    "#     tly = 435 - TOP_Y\n",
    "#     w = 70\n",
    "#     h = 45\n",
    "#     roi = raw_frame[tly:tly+h, tlx:tlx+w]\n",
    "    \n",
    "#     # Check if white directly on BGR image\n",
    "#     mean_val = roi.mean()  # Average across all pixels AND all channels\n",
    "    \n",
    "#     # If all channels are ~255, mean will be ~255\n",
    "#     return mean_val > 250\n",
    "\n",
    "# def test_runway_reward(raw_frame):\n",
    "#     tlx = RUNWAY_X - TOP_X\n",
    "#     tly = RUNWAY_Y - TOP_Y\n",
    "#     w = RUNWAY_W\n",
    "#     h = RUNWAY_H\n",
    "#     roi = raw_frame[tly:tly+h, tlx:tlx+w]\n",
    "\n",
    "#     if len(roi.shape) == 3: #grayscale\n",
    "#         roi_gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
    "#     else:\n",
    "#         roi_gray = roid\n",
    "    \n",
    "#     platform_pixels = np.sum(roi_gray > 30)\n",
    "#     total_pixels = roi_gray.size\n",
    "#     platform_ratio = platform_pixels / total_pixels\n",
    "    \n",
    "#     return platform_ratio\n",
    "\n",
    "# while True:\n",
    "#     start_time = time.time()\n",
    "#     screenshot = np.array(sct.grab(monitor))\n",
    "#     img = cv2.cvtColor(screenshot, cv2.COLOR_BGRA2BGR)\n",
    "#     if test_game_over(img):\n",
    "#         num_g_over += 1\n",
    "#         print(f\"\\rgame over {num_g_over}\", end='', flush=True)\n",
    "#         time.sleep(0.7)\n",
    "#         pyautogui.click(900, 650)\n",
    "#         time.sleep(0.7)\n",
    "#         pyautogui.click(900, 650)\n",
    "#     else:\n",
    "#         pass\n",
    "#         # print(test_runway_reward(img))\n",
    "#     elapsed = time.time() - start_time\n",
    "#     if elapsed < 1:\n",
    "#             time.sleep(1 - elapsed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3de65712",
   "metadata": {},
   "outputs": [],
   "source": [
    "#IHAVENT CHECKED THE CLASS BELOW YET THIS IS JUST CHAT SO DONT TREAT IT AS SOLIDLY IMPLEMENTED\n",
    "\n",
    "class PPOBuffer:\n",
    "    def __init__(self, size, obs_shape, gamma=0.99, lam=0.95):\n",
    "        \"\"\"\n",
    "        size      : number of steps per rollout\n",
    "        obs_shape : shape of observation e.g. (RESOLUTION, RESOLUTION, FRAME_STACK)\n",
    "        gamma     : discount factor\n",
    "        lam       : GAE lambda\n",
    "        \"\"\"\n",
    "        self.size = size\n",
    "        self.gamma = gamma\n",
    "        self.lam = lam\n",
    "\n",
    "        # Allocate buffers\n",
    "        self.obs_buf = np.zeros((size, *obs_shape), dtype=np.float32)\n",
    "        self.act_buf = np.zeros(size, dtype=np.int32)\n",
    "        self.rew_buf = np.zeros(size, dtype=np.float32)\n",
    "        self.done_buf = np.zeros(size, dtype=np.float32)\n",
    "        self.val_buf = np.zeros(size, dtype=np.float32)\n",
    "        self.logp_buf = np.zeros(size, dtype=np.float32)\n",
    "\n",
    "        # To be computed later\n",
    "        self.adv_buf = np.zeros(size, dtype=np.float32)\n",
    "        self.ret_buf = np.zeros(size, dtype=np.float32)\n",
    "\n",
    "        self.ptr = 0        # next index to write\n",
    "        self.path_start = 0 # start index of current trajectory\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # Store one step of rollout data\n",
    "    # ---------------------------------------------------------\n",
    "    def store(self, obs, act, rew, done, val, logp):\n",
    "        assert self.ptr < self.size, \"PPOBuffer overflow!\"\n",
    "        self.obs_buf[self.ptr] = obs\n",
    "        self.act_buf[self.ptr] = act\n",
    "        self.rew_buf[self.ptr] = rew\n",
    "        self.done_buf[self.ptr] = done\n",
    "        self.val_buf[self.ptr] = val\n",
    "        self.logp_buf[self.ptr] = logp\n",
    "        self.ptr += 1\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # Finish trajectory and compute GAE + returns\n",
    "    # last_val is the value of the final observation (0 if done)\n",
    "    # ---------------------------------------------------------\n",
    "    def finish_trajectory(self, last_val=0):\n",
    "        \"\"\"\n",
    "        Called at trajectory end or when episode completes.\n",
    "        Computes GAE advantage & discounted returns.\n",
    "        \"\"\"\n",
    "        i1 = self.path_start\n",
    "        i2 = self.ptr\n",
    "\n",
    "        rewards = np.append(self.rew_buf[i1:i2], last_val)\n",
    "        values  = np.append(self.val_buf[i1:i2], last_val)\n",
    "\n",
    "        # GAE-Lambda advantage calculation\n",
    "        deltas = rewards[:-1] + self.gamma * values[1:] - values[:-1]\n",
    "\n",
    "        adv = np.zeros_like(deltas)\n",
    "        last_gae = 0\n",
    "        for t in reversed(range(len(deltas))):\n",
    "            last_gae = deltas[t] + self.gamma * self.lam * last_gae * (1 - self.done_buf[i1 + t])\n",
    "            adv[t] = last_gae\n",
    "\n",
    "        self.adv_buf[i1:i2] = adv\n",
    "        self.ret_buf[i1:i2] = adv + self.val_buf[i1:i2]\n",
    "\n",
    "        self.path_start = self.ptr  # next trajectory starts here\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # Retrieve all data, normalize adv, and reset pointer\n",
    "    # ---------------------------------------------------------\n",
    "    def prepare_for_training(self):\n",
    "        \"\"\"\n",
    "        Call this after all trajectories are collected and before get().\n",
    "        Normalizes advantages across the entire buffer.\n",
    "        \"\"\"\n",
    "        assert self.ptr == self.size, \"Buffer not full!\"\n",
    "    \n",
    "        # Normalize advantages\n",
    "        adv_mean = self.adv_buf.mean()\n",
    "        adv_std = self.adv_buf.std() + 1e-8\n",
    "        self.adv_buf = (self.adv_buf - adv_mean) / adv_std\n",
    "\n",
    "        \n",
    "    def get(self, batch_size=64):\n",
    "        \"\"\"Returns batches of rollout data.\"\"\"\n",
    "        assert self.ptr == self.size, \"Buffer not full!\"\n",
    "    \n",
    "        return {\n",
    "            'obs': self.obs_buf,\n",
    "            'act': self.act_buf,\n",
    "            'adv': self.adv_buf,\n",
    "            'ret': self.ret_buf,\n",
    "            'logp': self.logp_buf,\n",
    "            'val': self.val_buf\n",
    "        }\n",
    "    \n",
    "    def reset(self):\n",
    "        \"\"\"\n",
    "        Reset buffer for next rollout collection.\n",
    "        Call this after training is done for the epoch.\n",
    "        \"\"\"\n",
    "        self.ptr = 0\n",
    "        self.path_start = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4dcc7a91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Configuration:\n",
      "  Learning Rate: 0.0003\n",
      "  Steps per Epoch: 512\n",
      "  Total Epochs: 150\n",
      "  Gamma: 0.99, GAE Lambda: 0.95\n",
      "  Clip Ratio: 0.2\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# TRAINING CONFIGURATION AND HYPERPARAMETERS\n",
    "# ============================================================================\n",
    "\n",
    "# Training hyperparameters\n",
    "LEARNING_RATE = 3e-4\n",
    "CLIP_RATIO = 0.2\n",
    "VALUE_COEF = 0.5\n",
    "ENTROPY_COEF = 0.025\n",
    "MAX_GRAD_NORM = 0.5\n",
    "\n",
    "# Rollout parameters\n",
    "STEPS_PER_EPOCH = 512  # Number of steps per training epoch\n",
    "TRAIN_EPOCHS = 150     # Total number of epochs\n",
    "MINI_BATCH_SIZE = 64    # Size of mini-batches for SGD\n",
    "UPDATE_EPOCHS = 5      # Number of epochs to train on each batch\n",
    "\n",
    "# Discount and GAE\n",
    "GAMMA = 0.99\n",
    "GAE_LAMBDA = 0.95\n",
    "\n",
    "# Logging and checkpointing\n",
    "LOG_INTERVAL = 3          # Log every N epochs\n",
    "SAVE_INTERVAL = 25         # Save model every N epochs\n",
    "EVAL_EPISODES = 10          # Number of episodes for evaluation\n",
    "\n",
    "# Create directories for saving\n",
    "import os\n",
    "os.makedirs('checkpoints', exist_ok=True)\n",
    "os.makedirs('logs', exist_ok=True)\n",
    "\n",
    "print(\"Training Configuration:\")\n",
    "print(f\"  Learning Rate: {LEARNING_RATE}\")\n",
    "print(f\"  Steps per Epoch: {STEPS_PER_EPOCH}\")\n",
    "print(f\"  Total Epochs: {TRAIN_EPOCHS}\")\n",
    "print(f\"  Gamma: {GAMMA}, GAE Lambda: {GAE_LAMBDA}\")\n",
    "print(f\"  Clip Ratio: {CLIP_RATIO}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a9d9d191",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training functions defined!\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# PPO TRAINING FUNCTIONS\n",
    "# ============================================================================\n",
    "\n",
    "def compute_loss(model, obs, actions, advantages, returns, old_log_probs, old_values):\n",
    "    \"\"\"\n",
    "    Compute PPO loss with clipping.\n",
    "    \n",
    "    Args:\n",
    "        model: PPOActorCritic model\n",
    "        obs: observations (batch_size, H, W, C)\n",
    "        actions: actions taken (batch_size,)\n",
    "        advantages: advantage estimates (batch_size,)\n",
    "        returns: discounted returns (batch_size,)\n",
    "        old_log_probs: old action log probabilities (batch_size,)\n",
    "        old_values: old value estimates (batch_size,)\n",
    "    \n",
    "    Returns:\n",
    "        total_loss, policy_loss, value_loss, entropy\n",
    "    \"\"\"\n",
    "    # Get current policy and value predictions\n",
    "    logits, values = model(obs, training=True)\n",
    "    values = tf.squeeze(values, axis=-1)\n",
    "    \n",
    "    # Compute log probabilities of actions\n",
    "    action_dist = tf.compat.v1.distributions.Categorical(logits=logits)\n",
    "    log_probs = action_dist.log_prob(actions)\n",
    "    \n",
    "    # Compute entropy for exploration bonus\n",
    "    entropy = tf.reduce_mean(action_dist.entropy())\n",
    "    \n",
    "    # Compute ratio for PPO\n",
    "    ratio = tf.exp(log_probs - old_log_probs)\n",
    "    \n",
    "    # Normalize advantages\n",
    "    advantages = (advantages - tf.reduce_mean(advantages)) / (tf.math.reduce_std(advantages) + 1e-8)\n",
    "    \n",
    "    # Policy loss with clipping\n",
    "    policy_loss_1 = -advantages * ratio\n",
    "    policy_loss_2 = -advantages * tf.clip_by_value(ratio, 1 - CLIP_RATIO, 1 + CLIP_RATIO)\n",
    "    policy_loss = tf.reduce_mean(tf.maximum(policy_loss_1, policy_loss_2))\n",
    "    \n",
    "    # Value loss with clipping\n",
    "    value_pred_clipped = old_values + tf.clip_by_value(\n",
    "        values - old_values, -CLIP_RATIO, CLIP_RATIO\n",
    "    )\n",
    "    value_loss_1 = tf.square(returns - values)\n",
    "    value_loss_2 = tf.square(returns - value_pred_clipped)\n",
    "    value_loss = 0.5 * tf.reduce_mean(tf.maximum(value_loss_1, value_loss_2))\n",
    "    \n",
    "    # Total loss\n",
    "    total_loss = policy_loss + VALUE_COEF * value_loss - ENTROPY_COEF * entropy\n",
    "    \n",
    "    return total_loss, policy_loss, value_loss, entropy\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def train_step(model, optimizer, obs, actions, advantages, returns, old_log_probs, old_values):\n",
    "    \"\"\"\n",
    "    Single training step with gradient computation.\n",
    "    \"\"\"\n",
    "    with tf.GradientTape() as tape:\n",
    "        total_loss, policy_loss, value_loss, entropy = compute_loss(\n",
    "            model, obs, actions, advantages, returns, old_log_probs, old_values\n",
    "        )\n",
    "    \n",
    "    # Compute gradients\n",
    "    gradients = tape.gradient(total_loss, model.trainable_variables)\n",
    "    \n",
    "    # Clip gradients\n",
    "    gradients, _ = tf.clip_by_global_norm(gradients, MAX_GRAD_NORM)\n",
    "    \n",
    "    # Apply gradients\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    \n",
    "    return total_loss, policy_loss, value_loss, entropy\n",
    "\n",
    "\n",
    "print(\"Training functions defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "eb306cba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rollout collection function defined!\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# DATA COLLECTION FUNCTION\n",
    "# ============================================================================\n",
    "\n",
    "def collect_rollout(env, model, buffer, num_steps):\n",
    "    \"\"\"\n",
    "    Collect trajectories by running the current policy in the environment.\n",
    "    \n",
    "    Args:\n",
    "        env: Run3Env instance\n",
    "        model: PPOActorCritic model\n",
    "        buffer: PPOBuffer instance\n",
    "        num_steps: number of steps to collect\n",
    "    \n",
    "    Returns:\n",
    "        ep_returns: list of episode returns\n",
    "        ep_lengths: list of episode lengths\n",
    "    \"\"\"\n",
    "    buffer.reset()  # Clear the buffer\n",
    "    \n",
    "    ep_returns = []\n",
    "    ep_lengths = []\n",
    "    current_ep_return = 0\n",
    "    current_ep_length = 0\n",
    "    \n",
    "    # Reset environment\n",
    "    obs = env.reset()\n",
    "    \n",
    "    for step in range(num_steps):\n",
    "        # Get action from policy\n",
    "        # Get action from policy\n",
    "        obs_tensor = tf.expand_dims(obs, axis=0)  # Add batch dimension\n",
    "        logits, value = model(obs_tensor, training=False)\n",
    "\n",
    "# Sample action from distribution (use logits, not probs!)\n",
    "        action_dist = tf.compat.v1.distributions.Categorical(logits=logits)\n",
    "        action_tensor = action_dist.sample()[0]\n",
    "        action = action_tensor.numpy()\n",
    "        log_prob = action_dist.log_prob(action_tensor).numpy()\n",
    "        value = value.numpy()[0, 0]\n",
    "        \n",
    "        # Take action in environment\n",
    "        next_obs, reward, done, info = env.step(action)\n",
    "        \n",
    "        # Store transition\n",
    "        buffer.store(obs, action, reward, done, value, log_prob)\n",
    "        \n",
    "        current_ep_return += reward\n",
    "        current_ep_length += 1\n",
    "        \n",
    "        obs = next_obs\n",
    "        \n",
    "        if done:\n",
    "            # Episode finished\n",
    "            buffer.finish_trajectory(0)  # Terminal state has value 0\n",
    "            ep_returns.append(current_ep_return)\n",
    "            ep_lengths.append(current_ep_length)\n",
    "            \n",
    "            # Reset for next episode\n",
    "            obs = env.reset()\n",
    "            current_ep_return = 0\n",
    "            current_ep_length = 0\n",
    "    \n",
    "    # If we ended mid-episode, bootstrap the value\n",
    "    if current_ep_length > 0:\n",
    "        obs_tensor = tf.expand_dims(obs, axis=0)\n",
    "        _, last_value = model(obs_tensor, training=False)\n",
    "        buffer.finish_trajectory(last_value.numpy()[0, 0])\n",
    "        ep_returns.append(current_ep_return)\n",
    "        ep_lengths.append(current_ep_length)\n",
    "    \n",
    "    buffer.prepare_for_training()\n",
    "\n",
    "    return ep_returns, ep_lengths\n",
    "\n",
    "\n",
    "print(\"Rollout collection function defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2b8254b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation function defined!\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# EVALUATION FUNCTION\n",
    "# ============================================================================\n",
    "\n",
    "def evaluate_policy(env, model, num_episodes=5):\n",
    "    \"\"\"\n",
    "    Evaluate the current policy deterministically (greedy).\n",
    "    \n",
    "    Args:\n",
    "        env: Run3Env instance\n",
    "        model: PPOActorCritic model\n",
    "        num_episodes: number of episodes to run\n",
    "    \n",
    "    Returns:\n",
    "        mean_return: average episode return\n",
    "        std_return: standard deviation of returns\n",
    "        mean_length: average episode length\n",
    "    \"\"\"\n",
    "    episode_returns = []\n",
    "    episode_lengths = []\n",
    "    \n",
    "    for ep in range(num_episodes):\n",
    "        obs = env.reset()\n",
    "        done = False\n",
    "        ep_return = 0\n",
    "        ep_length = 0\n",
    "        \n",
    "        while not done:\n",
    "            # Use greedy action (argmax)\n",
    "            obs_tensor = tf.expand_dims(obs, axis=0)\n",
    "            logits, _ = model(obs_tensor, training=False)\n",
    "            action = tf.argmax(logits[0]).numpy()\n",
    "            \n",
    "            obs, reward, done, info = env.step(action)\n",
    "            ep_return += reward\n",
    "            ep_length += 1\n",
    "            \n",
    "            # Safety: break if episode too long\n",
    "            if ep_length > 10000:\n",
    "                break\n",
    "        \n",
    "        episode_returns.append(ep_return)\n",
    "        episode_lengths.append(ep_length)\n",
    "    \n",
    "    return (\n",
    "        np.mean(episode_returns),\n",
    "        np.std(episode_returns),\n",
    "        np.mean(episode_lengths)\n",
    "    )\n",
    "\n",
    "\n",
    "print(\"Evaluation function defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "344df394",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing training components...\n",
      "Model initialized with 2,242,027 parameters\n",
      "\n",
      "Starting training...\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# INITIALIZE TRAINING COMPONENTS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"Initializing training components...\")\n",
    "\n",
    "env = Run3Env()\n",
    "model = PPOActorCritic(input_channels=FRAME_STACK, num_actions=NUM_ACTIONS)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE)\n",
    "buffer = PPOBuffer(\n",
    "    size=STEPS_PER_EPOCH,\n",
    "    obs_shape=(RESOLUTION, RESOLUTION, FRAME_STACK),\n",
    "    gamma=GAMMA,\n",
    "    lam=GAE_LAMBDA\n",
    ")\n",
    "\n",
    "# Build model by running a forward pass\n",
    "dummy_obs = tf.random.normal((1, RESOLUTION, RESOLUTION, FRAME_STACK))\n",
    "_ = model(dummy_obs)\n",
    "print(f\"Model initialized with {model.count_params():,} parameters\")\n",
    "\n",
    "# Training metrics\n",
    "training_stats = {\n",
    "    'epoch': [],\n",
    "    'mean_return': [],\n",
    "    'mean_length': [],\n",
    "    'policy_loss': [],\n",
    "    'value_loss': [],\n",
    "    'entropy': [],\n",
    "    'eval_return': [],\n",
    "    'eval_std': []\n",
    "}\n",
    "\n",
    "print(\"\\nStarting training...\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7c1bf418",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /var/folders/q_/y2tlnq4d3gl5gqxkc15y__ym0000gn/T/ipykernel_55550/1310795699.py:36: Categorical.__init__ (from tensorflow.python.ops.distributions.categorical) is deprecated and will be removed after 2019-01-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /var/folders/q_/y2tlnq4d3gl5gqxkc15y__ym0000gn/T/ipykernel_55550/1310795699.py:36: Categorical.__init__ (from tensorflow.python.ops.distributions.categorical) is deprecated and will be removed after 2019-01-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/elybrayboy/Desktop/csci1470-course/Run-3-Agent/run3_env/lib/python3.11/site-packages/tensorflow/python/ops/distributions/categorical.py:230: Distribution.__init__ (from tensorflow.python.ops.distributions.distribution) is deprecated and will be removed after 2019-01-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/elybrayboy/Desktop/csci1470-course/Run-3-Agent/run3_env/lib/python3.11/site-packages/tensorflow/python/ops/distributions/categorical.py:230: Distribution.__init__ (from tensorflow.python.ops.distributions.distribution) is deprecated and will be removed after 2019-01-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/elybrayboy/Desktop/csci1470-course/Run-3-Agent/run3_env/lib/python3.11/site-packages/tensorflow/python/util/dispatch.py:1260: multinomial (from tensorflow.python.ops.random_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.random.categorical` instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/elybrayboy/Desktop/csci1470-course/Run-3-Agent/run3_env/lib/python3.11/site-packages/tensorflow/python/util/dispatch.py:1260: multinomial (from tensorflow.python.ops.random_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.random.categorical` instead.\n",
      "/var/folders/q_/y2tlnq4d3gl5gqxkc15y__ym0000gn/T/ipykernel_55550/1679292621.py:40: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  self.logp_buf[self.ptr] = logp\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3/150 (343.6s)\n",
      "  Returns: 1.04 | Lengths: 9.3\n",
      "  Policy Loss: -0.0182\n",
      "  Value Loss: 21.7675\n",
      "  Entropy: 2.2538\n",
      "\n",
      "Epoch 6/150 (349.5s)\n",
      "  Returns: 0.20 | Lengths: 9.0\n",
      "  Policy Loss: -0.0271\n",
      "  Value Loss: 16.6255\n",
      "  Entropy: 2.2088\n",
      "\n",
      "Epoch 9/150 (325.4s)\n",
      "  Returns: 3.88 | Lengths: 11.1\n",
      "  Policy Loss: -0.0279\n",
      "  Value Loss: 27.8666\n",
      "  Entropy: 2.0575\n",
      "\n",
      "Epoch 12/150 (323.8s)\n",
      "  Returns: 7.01 | Lengths: 12.5\n",
      "  Policy Loss: -0.0175\n",
      "  Value Loss: 34.1855\n",
      "  Entropy: 2.1061\n",
      "\n",
      "Epoch 15/150 (330.8s)\n",
      "  Returns: 2.98 | Lengths: 10.4\n",
      "  Policy Loss: -0.0282\n",
      "  Value Loss: 20.7703\n",
      "  Entropy: 2.0067\n",
      "  [EVAL] Return: 7.24 Â± 8.22 | Length: 12.6\n",
      "\n",
      "Epoch 18/150 (310.2s)\n",
      "  Returns: 4.97 | Lengths: 11.6\n",
      "  Policy Loss: -0.0195\n",
      "  Value Loss: 47.4705\n",
      "  Entropy: 1.8683\n",
      "\n",
      "Epoch 21/150 (308.7s)\n",
      "  Returns: 3.98 | Lengths: 10.9\n",
      "  Policy Loss: -0.0165\n",
      "  Value Loss: 28.7975\n",
      "  Entropy: 1.6717\n",
      "\n",
      "Epoch 24/150 (291.2s)\n",
      "  Returns: 6.59 | Lengths: 12.8\n",
      "  Policy Loss: -0.0206\n",
      "  Value Loss: 31.4076\n",
      "  Entropy: 1.5656\n",
      "  [SAVED] Checkpoint: checkpoints/model_epoch_25.h5\n",
      "\n",
      "Epoch 27/150 (271.6s)\n",
      "  Returns: 11.90 | Lengths: 16.0\n",
      "  Policy Loss: -0.0139\n",
      "  Value Loss: 70.7678\n",
      "  Entropy: 1.3492\n",
      "\n",
      "Epoch 30/150 (272.6s)\n",
      "  Returns: 7.82 | Lengths: 13.1\n",
      "  Policy Loss: -0.0165\n",
      "  Value Loss: 43.4716\n",
      "  Entropy: 1.2163\n",
      "  [EVAL] Return: 40.03 Â± 107.02 | Length: 30.5\n",
      "\n",
      "Epoch 33/150 (283.3s)\n",
      "  Returns: 7.06 | Lengths: 12.8\n",
      "  Policy Loss: -0.0090\n",
      "  Value Loss: 24.5103\n",
      "  Entropy: 1.3671\n",
      "\n",
      "Epoch 36/150 (287.5s)\n",
      "  Returns: 7.09 | Lengths: 12.5\n",
      "  Policy Loss: -0.0197\n",
      "  Value Loss: 31.0670\n",
      "  Entropy: 1.4166\n",
      "\n",
      "Epoch 39/150 (227.0s)\n",
      "  Returns: 28.64 | Lengths: 24.4\n",
      "  Policy Loss: -0.0160\n",
      "  Value Loss: 164.4602\n",
      "  Entropy: 0.7887\n",
      "\n",
      "Epoch 42/150 (157.7s)\n",
      "  Returns: 983.12 | Lengths: 512.0\n",
      "  Policy Loss: 0.0276\n",
      "  Value Loss: 397.6926\n",
      "  Entropy: 0.5015\n",
      "\n",
      "Epoch 45/150 (322.1s)\n",
      "  Returns: 3.73 | Lengths: 10.9\n",
      "  Policy Loss: -0.0102\n",
      "  Value Loss: 28.7687\n",
      "  Entropy: 1.9505\n",
      "  [EVAL] Return: 3.19 Â± 8.12 | Length: 10.9\n",
      "\n",
      "Epoch 48/150 (332.6s)\n",
      "  Returns: 2.26 | Lengths: 10.0\n",
      "  Policy Loss: -0.0324\n",
      "  Value Loss: 26.2271\n",
      "  Entropy: 1.8835\n",
      "  [SAVED] Checkpoint: checkpoints/model_epoch_50.h5\n",
      "\n",
      "Epoch 51/150 (315.8s)\n",
      "  Returns: 5.34 | Lengths: 11.9\n",
      "  Policy Loss: -0.0208\n",
      "  Value Loss: 28.5453\n",
      "  Entropy: 1.7842\n",
      "\n",
      "Epoch 54/150 (319.4s)\n",
      "  Returns: 3.89 | Lengths: 11.6\n",
      "  Policy Loss: -0.0304\n",
      "  Value Loss: 16.1956\n",
      "  Entropy: 1.7348\n",
      "\n",
      "Epoch 57/150 (309.4s)\n",
      "  Returns: 8.23 | Lengths: 13.5\n",
      "  Policy Loss: -0.0109\n",
      "  Value Loss: 45.0193\n",
      "  Entropy: 1.6124\n",
      "\n",
      "Epoch 60/150 (314.2s)\n",
      "  Returns: 5.84 | Lengths: 11.9\n",
      "  Policy Loss: -0.0217\n",
      "  Value Loss: 23.7118\n",
      "  Entropy: 1.5460\n",
      "  [EVAL] Return: 17.45 Â± 30.50 | Length: 20.6\n",
      "\n",
      "Epoch 63/150 (304.1s)\n",
      "  Returns: 6.27 | Lengths: 12.5\n",
      "  Policy Loss: -0.0094\n",
      "  Value Loss: 16.6289\n",
      "  Entropy: 1.5309\n",
      "\n",
      "Epoch 66/150 (301.4s)\n",
      "  Returns: 7.72 | Lengths: 13.8\n",
      "  Policy Loss: -0.0276\n",
      "  Value Loss: 35.5637\n",
      "  Entropy: 1.5437\n",
      "\n",
      "Epoch 69/150 (295.7s)\n",
      "  Returns: 10.81 | Lengths: 15.5\n",
      "  Policy Loss: -0.0270\n",
      "  Value Loss: 46.4503\n",
      "  Entropy: 1.4970\n",
      "\n",
      "Epoch 72/150 (283.5s)\n",
      "  Returns: 12.34 | Lengths: 15.5\n",
      "  Policy Loss: -0.0104\n",
      "  Value Loss: 66.9201\n",
      "  Entropy: 1.3670\n",
      "\n",
      "Epoch 75/150 (319.7s)\n",
      "  Returns: 4.30 | Lengths: 11.6\n",
      "  Policy Loss: -0.0374\n",
      "  Value Loss: 20.5663\n",
      "  Entropy: 1.6478\n",
      "  [EVAL] Return: 40.30 Â± 38.05 | Length: 30.9\n",
      "  [SAVED] Checkpoint: checkpoints/model_epoch_75.h5\n",
      "\n",
      "Epoch 78/150 (300.7s)\n",
      "  Returns: 4.00 | Lengths: 11.9\n",
      "  Policy Loss: -0.0281\n",
      "  Value Loss: 19.3462\n",
      "  Entropy: 1.4838\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      6\u001b[39m epoch_start_time = time.time()\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# === 1. Collect rollout data ===\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m ep_returns, ep_lengths = \u001b[43mcollect_rollout\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mSTEPS_PER_EPOCH\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     11\u001b[39m mean_return = np.mean(ep_returns) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(ep_returns) > \u001b[32m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[32m0\u001b[39m\n\u001b[32m     12\u001b[39m mean_length = np.mean(ep_lengths) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(ep_lengths) > \u001b[32m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[32m0\u001b[39m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 43\u001b[39m, in \u001b[36mcollect_rollout\u001b[39m\u001b[34m(env, model, buffer, num_steps)\u001b[39m\n\u001b[32m     40\u001b[39m value = value.numpy()[\u001b[32m0\u001b[39m, \u001b[32m0\u001b[39m]\n\u001b[32m     42\u001b[39m \u001b[38;5;66;03m# Take action in environment\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m43\u001b[39m next_obs, reward, done, info = \u001b[43menv\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     45\u001b[39m \u001b[38;5;66;03m# Store transition\u001b[39;00m\n\u001b[32m     46\u001b[39m buffer.store(obs, action, reward, done, value, log_prob)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 83\u001b[39m, in \u001b[36mRun3Env.step\u001b[39m\u001b[34m(self, action)\u001b[39m\n\u001b[32m     81\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mstep\u001b[39m(\u001b[38;5;28mself\u001b[39m, action): \u001b[38;5;66;03m#NOT FINISHED DONT TOUCH\u001b[39;00m\n\u001b[32m     82\u001b[39m     \u001b[38;5;66;03m# step_start = time.time()\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m83\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_execute_action\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     85\u001b[39m     \u001b[38;5;66;03m# Capture new frame\u001b[39;00m\n\u001b[32m     86\u001b[39m     raw = \u001b[38;5;28mself\u001b[39m.capture_raw()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 133\u001b[39m, in \u001b[36mRun3Env._execute_action\u001b[39m\u001b[34m(self, action)\u001b[39m\n\u001b[32m    131\u001b[39m     time.sleep(duration)\n\u001b[32m    132\u001b[39m     pyautogui.keyUp(key)\n\u001b[32m--> \u001b[39m\u001b[32m133\u001b[39m time.sleep(\u001b[32m0.25\u001b[39m-duration)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# MAIN TRAINING LOOP\n",
    "# ============================================================================\n",
    "\n",
    "for epoch in range(TRAIN_EPOCHS):\n",
    "    epoch_start_time = time.time()\n",
    "    \n",
    "    # === 1. Collect rollout data ===\n",
    "    ep_returns, ep_lengths = collect_rollout(env, model, buffer, STEPS_PER_EPOCH)\n",
    "    \n",
    "    mean_return = np.mean(ep_returns) if len(ep_returns) > 0 else 0\n",
    "    mean_length = np.mean(ep_lengths) if len(ep_lengths) > 0 else 0\n",
    "    \n",
    "    # === 2. Get training data from buffer ===\n",
    "    data = buffer.get()\n",
    "    obs_buf = data['obs']\n",
    "    act_buf = data['act']\n",
    "    adv_buf = data['adv']\n",
    "    ret_buf = data['ret']\n",
    "    logp_buf = data['logp']\n",
    "    val_buf = data['val']\n",
    "    \n",
    "    # === 3. Train on the collected data ===\n",
    "    total_losses = []\n",
    "    policy_losses = []\n",
    "    value_losses = []\n",
    "    entropies = []\n",
    "    \n",
    "    # Perform multiple epochs of training on the same batch\n",
    "    for i in range(UPDATE_EPOCHS):\n",
    "        # Shuffle indices\n",
    "        indices = np.arange(len(obs_buf))\n",
    "        np.random.shuffle(indices)\n",
    "        \n",
    "        # Train on mini-batches\n",
    "        for start in range(0, len(obs_buf), MINI_BATCH_SIZE):\n",
    "            end = start + MINI_BATCH_SIZE\n",
    "            batch_idx = indices[start:end]\n",
    "            \n",
    "            batch_obs = tf.constant(obs_buf[batch_idx])\n",
    "            batch_act = tf.constant(act_buf[batch_idx])\n",
    "            batch_adv = tf.constant(adv_buf[batch_idx])\n",
    "            batch_ret = tf.constant(ret_buf[batch_idx])\n",
    "            batch_logp = tf.constant(logp_buf[batch_idx])\n",
    "            batch_val = tf.constant(val_buf[batch_idx])\n",
    "            \n",
    "            # Perform gradient update\n",
    "            total_loss, policy_loss, value_loss, entropy = train_step(\n",
    "                model, optimizer, batch_obs, batch_act,\n",
    "                batch_adv, batch_ret, batch_logp, batch_val\n",
    "            )\n",
    "            \n",
    "            total_losses.append(total_loss.numpy())\n",
    "            policy_losses.append(policy_loss.numpy())\n",
    "            value_losses.append(value_loss.numpy())\n",
    "            entropies.append(entropy.numpy())\n",
    "    \n",
    "    # === 4. Logging ===\n",
    "    epoch_time = time.time() - epoch_start_time\n",
    "    \n",
    "    if (epoch + 1) % LOG_INTERVAL == 0:\n",
    "        print(f\"\\nEpoch {epoch + 1}/{TRAIN_EPOCHS} ({epoch_time:.1f}s)\")\n",
    "        print(f\"  Returns: {mean_return:.2f} | Lengths: {mean_length:.1f}\")\n",
    "        print(f\"  Policy Loss: {np.mean(policy_losses):.4f}\")\n",
    "        print(f\"  Value Loss: {np.mean(value_losses):.4f}\")\n",
    "        print(f\"  Entropy: {np.mean(entropies):.4f}\")\n",
    "        \n",
    "        # Periodic evaluation\n",
    "        if (epoch + 1) % (LOG_INTERVAL * 5) == 0:\n",
    "            eval_return, eval_std, eval_length = evaluate_policy(env, model, EVAL_EPISODES)\n",
    "            print(f\"  [EVAL] Return: {eval_return:.2f} Â± {eval_std:.2f} | Length: {eval_length:.1f}\")\n",
    "            training_stats['eval_return'].append(eval_return)\n",
    "            training_stats['eval_std'].append(eval_std)\n",
    "    \n",
    "    # Store metrics\n",
    "    training_stats['epoch'].append(epoch + 1)\n",
    "    training_stats['mean_return'].append(mean_return)\n",
    "    training_stats['mean_length'].append(mean_length)\n",
    "    training_stats['policy_loss'].append(np.mean(policy_losses))\n",
    "    training_stats['value_loss'].append(np.mean(value_losses))\n",
    "    training_stats['entropy'].append(np.mean(entropies))\n",
    "    \n",
    "    # === 5. Save checkpoint ===\n",
    "    if (epoch + 1) % SAVE_INTERVAL == 0:\n",
    "        checkpoint_path = f'checkpoints/model_epoch_{epoch + 1}.h5'\n",
    "        model.save_weights(checkpoint_path)\n",
    "        print(f\"  [SAVED] Checkpoint: {checkpoint_path}\")\n",
    "\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2499d55-efb1-4ad2-bdbc-a662990bf2da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#JUST FOR LOADING AND EVALUATING A MODEL\n",
    "\n",
    "env = Run3Env()\n",
    "model = PPOActorCritic(input_channels=FRAME_STACK, num_actions=NUM_ACTIONS)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE)\n",
    "buffer = PPOBuffer(\n",
    "    size=STEPS_PER_EPOCH,\n",
    "    obs_shape=(RESOLUTION, RESOLUTION, FRAME_STACK),\n",
    "    gamma=GAMMA,\n",
    "    lam=GAE_LAMBDA\n",
    ")\n",
    "\n",
    "# Build model by running a forward pass\n",
    "dummy_obs = tf.random.normal((1, RESOLUTION, RESOLUTION, FRAME_STACK))\n",
    "_ = model(dummy_obs)\n",
    "print(f\"Model initialized with {model.count_params():,} parameters\")\n",
    "\n",
    "model_path = 'checkpoints/model_epoch_75.h5'  # or whichever epoch you want\n",
    "model.load_weights(model_path)\n",
    "print(f\"Loaded model from {model_path}\")\n",
    "\n",
    "eval_return, eval_std, eval_length = evaluate_policy(env, model, EVAL_EPISODES)\n",
    "print(f\"  [EVAL] Return: {eval_return:.2f} Â± {eval_std:.2f} | Length: {eval_length:.1f}\")\n",
    "training_stats['eval_return'].append(eval_return)\n",
    "training_stats['eval_std'].append(eval_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d78a597-272a-4951-8f32-aff17cf1cabf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "run3_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
